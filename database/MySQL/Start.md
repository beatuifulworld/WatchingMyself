[TOC]

#  Start

# MySQL

> 增删改数据(DML)
>
> 修改表结构(DDL)

## 存储引擎

### InnoDB

InnoDB 是 MySQL **默认的事务型存储引擎**，只要在需要它不支持的特性时，才考虑使用其他存储引擎。

InnoDB 采用 **MVCC 来支持高并发**，并且实现了四个标准隔离级别(未提交读、提交读、可重复读、可串行化)。其默认级别时可重复读（REPEATABLE READ），在可重复读级别下，通过 **MVCC + Next-Key Locking 防止幻读**。

主索引时**聚簇索引**，在索引中保存了数据，从而避免直接读取磁盘，因此对主键查询有很高的性能。

InnoDB 内部做了很多优化，包括从磁盘读取数据时采用的**可预测性读**，能够自动在内存中创建 **hash 索引以加速读操作的自适应哈希索引**，以及能够**加速插入操作的插入缓冲区**等。

InnoDB 支持真正的**在线热备份**，MySQL 其他的存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合的场景中，停止写入可能也意味着停止读取。

### MyISAM

设计简单，数据以紧密格式存储。对于**只读数据，或者表比较小、可以容忍修复操作**，则依然可以使用它。

提供了大量的特性，包括**压缩表、空间数据索引**等。

**不支持事务**。

**不支持行级锁**，只能对整张表加锁，读取时会对需要读到的所有表加**共享锁**，写入时则对表加**排它锁**。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为**并发插入（CONCURRENT INSERT）**。

可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些**数据丢失**，而且修复操作是非常**慢**的。

如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，**不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区**，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。

### 比较

- 事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。
- 并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。
- 外键：InnoDB 支持外键。
- 备份：InnoDB 支持在线热备份。
- 崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。
- 其它特性：MyISAM 支持压缩表和空间数据索引。

## 日志

MySQL执行一条语句需要经过以下步骤

![](https://raw.githubusercontent.com/catwithtudou/photo/master/20191013114135.png)

- Server层：主要处理功能层面的事情
- 引擎层：负责存储相关的具体事宜

> 查看空闲连接列表：show processlist
>
> 若Command列中为Sleep值则说明有一个空闲连接；
>
> 时间参数wait_timeout控制数据库连接超时，默认为8个小时；
>
> 除了重新连接，还可以通过长连接，但长连接会使内存消耗过大，只有在链接中断的时候才能够得到释放，若一直使用长连接则可能导致OOM（Out Of Memory）即导致MySQL重启，解决办法可以有定期断开长连接，使用一段时间后，或者程序里面判断执行过一个占用内存比较大的查询后就断开连接，需要的时候重连就好了；执行比较大的一个查询后，执行**mysql_reset_connection**可以重新初始化连接资源。这个过程相比上面一种会好点，不需要重连，但是会初始化连接的状态。
>
> 缓存的失效很容易，只要对表有任何的更新则会清除所有查询的缓存；
>
> 把**query_cache_type**设置成为DEMAND，这样SQL默认不适用缓存，想用缓存就用SQL_CACHE；

### redolog

- WAL（Write-Ahead Logging）策略

  先写日志,等系空闲的时候或者说日志空间满了的时候再写磁盘。

  > flush时机
  >
  > ![image-20201109194312990](http://img.zhengyua.cn/img/20201109194313.png)
  >
  > flush时机：使用innodb_io_capacity这个参数了，即代表InnoDB的磁盘能力，**这个值建议设置成磁盘的IOPS，磁盘的IOPS可以通过fio这个工具来测试**。
  >
  > 在上面四种场景中后面两种其实时比较与“性能”问题相关不大，而我们需要注意的是前面两种场景下的性能问题:
  >
  > - **日志写满**，更新全部堵住，写性能跌为0，这种情况对敏感业务来说，是不能接受的；
  > - 一个查询要**淘汰的脏页个数太多**，会导致查询的响应时间明显变长。
  >
  > **连带责任**：会将周围的脏页一起flush。
  >
  > 但是现在都是固态硬盘了，innodb_flush_neighbors=0这个参数可以不产生连带制，在MySQL 8.0中，innodb_flush_neighbors参数的默认值已经是0了。
  >
  > ![image-20201109194837828](http://img.zhengyua.cn/img/20201109194837.png)

- 循环写且空间固定

  ![image-20201107213021905](C:%5CUsers%5Ctudou%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201107213021905.png)

- crash-safe（异常恢复）

- InnoDB引擎日志模块

- 存储物理日志即记录“在某个表中做了什么修改”

### binlog

- Server层日志模块

- 无crash-safe能力

- 可追加写入

- 两种模式

  statement格式（记录sql语句）

  row格式（行的内容包括更新前和更新后）

- 存储逻辑日志即记录语句的原始逻辑

### undolog

- 回滚和多版本控制MVCC

- 存储逻辑日志

  注意会记录相反的update

### 更新语句的内部流程

Server层即执行器和引擎层即InnoDB层是如何处理这一个语句的整个流程：

1. 执行器**先找到引擎**，引擎通过树搜索找到ID=2这一行，如果ID=2这一行所在的数据页**本来就在内存中**，就直接返回给执行器，否则需要先**从磁盘读入内存**，然后内存再返回；
2. **执行器**拿到搜索到的这一行数据，把这个值加上1，得到新的一行数据，再调用**引擎接口写入**这行新数据；
3. 引擎将这行新数据**更新到内存**中，同时将这个更新操作记录到**redolog里**面，此时redolog处于**prepare状态**，记录完成后告知执行器执行完成，随时可以提交事务；
4. 执行器生成这个操作的binlog，并把**binlog写入磁盘**；
5. 执行器调用引擎的**提交事务接口**，引擎把刚刚写入的redolog改成提交**commit状态**，最后更新完成。

> redolog记录即使异常重启都会刷新到磁盘|binlog记录的主要用于备份。
>
> 浅色框代表引擎层,深色框代表Server层
>
> ![](https://raw.githubusercontent.com/catwithtudou/photo/master/20191013194253.png)

**两阶段提交**：

- **保证两份日志之间的逻辑一致**，保证临时库与线上库数据一致。

任何一个阶段的crash：

- 若在commit状态前崩溃时直接将事务回滚该事务就失效
- 若在commit状态时崩溃恢复后会继续提交该commit状态

> 写完第一个日志后,第二个日志还没有写完期间发生crash：
>
> - 先写redolog后写binlog
>
> redolog写完系统即使崩溃也能通过内存存入恢复，且恢复更新后的值，但binlog备份不完全，即不保证与线上库数据完全一致。
>
> - 先写binlog再写redolog
>
> 原值不发生变化，binlog记录了更新逻辑，binlog进行恢复时会多出来一个事务即会更新原值导致与实际值不一致。

## 事务

- 事务：**保证一组数据库操作要么全部成功要么全部失败**

> 在MySQL中事务支持是在引擎层实现的，并不是所有的引擎都支持事务，如MyISAM引擎就不支持事务。

**事务四大特性ACID**：

- Atomicity原子性

  事务是一个**原子性质**的操作单元；

- Consistency一致性

  在事务**开始之前和完成之后**数据保证为一致状态即数据库的完整性；

- Isolation隔离性

  允许多个并发事务同对数据进行操作时保证**各个事务相互独立**；

- Durability持久性

  事务处理结束后其对数据库的修改就是**永久性的**，即使系统故障也不会丢失。

### 事务隔离

SQL中标准的事务隔离级别以下：

- **读未提交**（read uncommitted）

  事务没提交也能被看到读到（变更操作），

  允许脏读取，但不允许更新丢失；

- **读提交**（read committed）

  事务提交才能被看到读到（变更操作），

  允许不可重复读取，但不允许脏读取；

- **可重复读**（repeatable read）

  事务执行过程中读到的总是与启动时读到的数据一致，且提交后才能被读到，

  禁止不可重复读取和脏读取，但是有时可能出现幻读数据；

- **串行化**（serializable）

  保证其同步执行完成，提供严格的事务隔离。

**隔离度越高则效率越低**：隔离级别越高越能保证数据的完整性和一致性，但是对并发性能的影响也越大。

> **脏读**（Dirty read）：一个事务中访问到了另外一个事务未提交的数据；
>
> **不可重复读**（non-repeatable read）：一个事务读取同一条记录得到的结果不一致；
>
> **幻读**（phantom read）：一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。
>
> **丢失更新**：一个事务的更新操作会被另一个事务的更新操作所覆盖。

**逻辑视图创建时机**：

- 读未提交：直接返回记录的最新值,没有视图概念；

- 读提交：级别下是在每个SQL语句开始执行的时候创建；
- 可重复读：在事务启动的时候就被创建且整个事务期间都会用这一个视图；
- 串行化：直接用锁的方式来避免并行访问。

**事务隔离实现**：

![](https://raw.githubusercontent.com/catwithtudou/photo/master/20191016200411.png)

- 多版本并发控制(MVCC)—undolog

### 自增主键

- 在以下场景下自增主键可能不连续：唯一键冲突|**事务回滚**|自增主键的批量申请。

深层次原因是不判断自增主键**是否已存在**和**减少加锁的时间范围和粒度**，为了更高的性能，**自增主键不能回退**，自增主键不连续。

- 自增主键实现唯一性：自增值加1，**自增锁控制并发**；

- 自增主键的生成性能：需要测试，数据库的自增主键也用做生成唯一数字，作为其他单号；

- 自增主键的最大值：数字总有个范围，到了最大值可以当做字符串的一部分，然后再自增拼接上另一部分；

作用：让主键索引尽量地保持递增顺序插入，**避免页分裂，使索引更紧凑**。

保存机制：不同的存储引擎不一样。

> MyISAM 引擎的自增值保存在**数据文件**中。
>
> InnoDB 引擎的自增值，先是保存在了内存里，到了 MySQL 8.0 版本后，才有了“自增值持久化”的能力，放在了**redolog**里。

修改机制：在 MySQL 里面，如果字段 id 被定义为 AUTO_INCREMENT，在插入一行数据的时候，自增值的行为如下：

1. 如果插入数据时 id 字段**指定为 0、null 或未指定值**，那么就把这个表当前的 AUTO_INCREMENT 值填到自增字段；
2. 如果插入数据时 id 字段指定了具体的值，就直接使用**语句里指定的值**。

假设，某次要插入的值是 X，当前的自增值是 Y

1. 如果 X<Y，那么这个表的**自增值不变**；
2. 如果 X≥Y，就需要把当前自增值修改为**新的自增值**。

- innodb_autoinc_lock_mode设置问题

在生产上，尤其是有 insert … select 这种批量插入数据的场景时，从并发插入数据性能的角度考虑，建议设置：innodb_autoinc_lock_mode=2 ，并且 binlog_format=row。

这样做，既能提升并发性，又不会出现数据一致性问题。需要注意的是，我这里说的批量插入数据，包含的语句类型是 insert … select、replace … select 和 load data 语句。

## 索引

### 索引介绍

- 索引：**提高数据查询的效率**
- 索引往往是存储在**磁盘**上的文件中的

> 我们通常所说的索引，包括聚集索引、覆盖索引、组合索引、前缀索引、唯一索引等，没有特别说明，默认都是使用B+树结构组织（多路搜索树，并不一定是二叉的）的索引。

索引的优势与劣势：

**优势**：

- 提高数据检索的效率，降低数据库的IO成本；
- 通过索引列对数据进行排序，降低数据排序的成本，降低了CPU的消耗，以及避免创建临时表。

**劣势**：

- 索引会占据磁盘空间；
- 索引虽然会提高查询效率，但是会降低更新表的效率。

### 索引的使用条件

- 对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效；

  > 因为遍历是不需要回表的。

- 对于中到大型的表，索引就非常有效；

- 但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。

### 索引类型

- 主键索引（聚簇索引（clustered index））

  叶子节点存的值为整行数据

- 非主键索引（二级索引（secondary index））

  叶子节点存的值为主键的值

> - 主键索引：索引列中的值必须是唯一的，不允许有空值；
> - 普通索引：MySQL中基本索引类型，没有什么限制，允许在定义索引的列中插入重复值和空值；
> - 唯一索引：索引列中的值必须是唯一的，但是允许为空值；
>
> - 全文索引：只能在文本类型CHAR,VARCHAR,TEXT类型字段上创建全文索引。字段长度比较大时，如果创建普通索引，在进行like模糊查询时效率比较低，这时可以创建全文索引。MyISAM和InnoDB中都可以使用全文索引。
>
>   查找条件使用 MATCH AGAINST，而不是普通的 WHERE。
>
>   全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。
>
> - 空间索引：MySQL在5.7之后的版本支持了空间索引，而且支持OpenGIS几何数据模型。MySQL在空间索引这方面遵循OpenGIS几何数据模型规则。
>
> - 前缀索引：在文本类型如CHAR,VARCHAR,TEXT类列上创建索引时，可以指定索引列的长度，但是数值类型不能指定。
>
> - 其他（按照索引列数量分类）：
>
> 1. 单列索引
> 2. 组合索引
>
> 组合索引的使用，需要遵循**最左前缀匹配原则（最左匹配原则）**。一般情况下在条件允许的情况下使用组合索引替代多个单列索引使用。

### 索引的数据结构

**哈希表**：

不支持范围快速查找，范围查找时只能通过全表扫描方式；

适用于等值查询场景，如Memcached及其他NoSQL引擎。

**有序数组**：

适用于区间查询和等值查询场景，如静态存储引擎。

**二叉查找树**：

保证每次查找折折半而减少IO次数，避免不稳定情况退化为链表。

**平衡二叉树**：

性能接近于二分查找法，时间复杂度是 O(log2n)，但时间复杂度和树高相关即树的高度就等于每次查询数据时磁盘IO操作的次数，且平衡二叉树不支持范围查询快速查找。

**B树**：改造二叉树

优化的重点就是尽量减少磁盘 IO 操作。访问二叉树的每个节点就会发生一次IO，如果想要减少磁盘IO操作，就需要尽量降低树的高度。

因为在MySQL的InnoDB存储引擎一次IO会读取的一页（默认一页16K）的数据量，而二叉树一次IO有效数据量只有16字节，空间利用率极低。为了最大化利用一次IO空间，则让每个节点尽可能多的存储数据，即让二叉树变成多叉树。

这种数据结构我们称为B树，B树是一种多叉平衡查找树。

B树可以优化的地方：

1. B树不支持范围查询的快速查找；
2. 如果data存储的是行记录，行的大小随着列数的增多，所占空间会变大，磁盘IO次数就会变大。

> 主要特点：
>
> - B树的节点中存储着多个元素，每个内节点有多个分叉；
> - 节点中的元素包含键值和数据，节点中的键值从大到小排列。也就是说，在所有的节点都储存数据；
> - 父节点当中的元素不会出现在子节点中；
> - 所有的叶子结点都位于同一层，叶节点具有相同的深度，叶节点之间没有指针连接。
>
> ![image-20201108082337723](http://img.zhengyua.cn/img/20201108082344.png)
>
> ![image-20201108082549368](http://img.zhengyua.cn/img/20201108082549.png)

**B+树**：改造B树

在B树基础上，MySQL在B树的基础上继续改造，使用B+树构建索引。B+树和B树最主要的区别在于**非叶子节点是否存储数据**的问题，且叶子节点之间使用双向指针连接，即最底层的叶子节点形成了一个双向有序列表。

![image-20201108091518072](http://img.zhengyua.cn/img/20201108091518.png)

B+树的最底层叶子节点包含了所有的索引项，即每次查找都需要检索到叶子节点。也存在索引覆盖查询的情况，在索引中数据满足了当前查询语句所需要的全部数据，此时只需要找到索引即可立刻返回，不需要检索到最底层的叶子节点。

> 等值查询：
>
> ![image-20201108091743971](http://img.zhengyua.cn/img/20201108091744.png)
>
> 
>
> 范围查询：
>
> ![image-20201108091902571](http://img.zhengyua.cn/img/20201108091902.png)

#### 红黑树|B+树|B树

**红黑树与B+树**：

红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，主要有以下两个原因：

- 磁盘IO次数

  相对于红黑树其B+树的磁盘IO次数更少。

- 磁盘预读特性

  为减少磁盘IO操作，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道。每次回读取页的整数倍。

> 操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。

**B+树与B树**：

- B+树的磁盘IO更低

  B+ 树的内部节点并没有指向关键字具体信息的指针。因此其内部节点相对 B 树更小。若把所有同一内部结点的关键词存放在同一盘块中，一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。

- B+ 树的查询效率更加稳定

  所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。

- B+ 树元素遍历效率高

  B+树只要遍历叶子节点就可以实现整棵树的遍历，即能够实现范围查找，而B树不支持这样的操作（或者说效率太低）。



### 索引实现

#### MyIsam索引

MyISAM的数据文件和索引文件是**分开存储**的。

MyISAM使用B+树构建索引树时，叶子节点中存储的键值为索引列的值，数据为索引所在行的**磁盘地址**。

**主键索引**：

![image-20201108092405923](http://img.zhengyua.cn/img/20201108092406.png)

磁盘IO次数：索引检索+记录数据检索

![image-20201108092943543](http://img.zhengyua.cn/img/20201108092943.png)

**辅助索引**：

与主键唯一的区别就是辅助索引的键值可以重复。

查询数据时，由于辅助索引的键值不唯一，可能存在多个拥有相同的记录，所以即使是等值查询，也需要按照范围查询的方式在辅助索引树中检索数据。

#### InnoDB索引

**主键索引**：

每个InnoDB表都有一个聚簇索引 ，聚簇索引使用**B+树构建**，叶子节点存储的数据是**整行记录**。InnoDB创建索引的具体规则如下：

- 定义主键PRIMARY KEY；
- 没有定义主键时选择第一个不为NULL的唯一索引列；
- 若以上两个都没有则使用一个6字节长整型的隐式字段ROWID字段构建聚簇索引，且ROWID字段会在插入新行时自动递增。

除聚簇索引之外的所有索引都称为辅助索引。辅助索引中的叶子节点存储的数据是该行的**主键值**。在检索时，InnoDB使用此主键值在聚簇索引中搜索行记录。

> InnoDB的数据和索引存储在一个文件t_user_innodb.ibd中。
>
> InnoDB的数据组织方式，是聚簇索引。

![image-20201108103102831](http://img.zhengyua.cn/img/20201108103103.png)

**辅助索引**：

除聚簇索引之外的所有索引都称为辅助索引存储主键值而非磁盘地址。

![image-20201108103137279](http://img.zhengyua.cn/img/20201108103137.png)

磁盘IO数：辅助索引+获取记录回表

**组合索引**：

数据结构如下：

![image-20201108150404273](http://img.zhengyua.cn/img/20201108150404.png)

> 组合索引的查询过程：
>
> ![image-20201108150550190](http://img.zhengyua.cn/img/20201108150550.png)
>
> 

**最左匹配原则**：

最左前缀匹配原则和联合索引的**索引存储结构和检索方式**是有关系的。

组合索引的最左前缀匹配原则：**使用组合索引查询时，mysql会一直向右匹配直至遇到范围查询**(>、<、between、like)就停止匹配。

**覆盖索引**：

覆盖索引**并不是说是索引结构**，覆盖索引是一种很常用的**优化手段**。

因为在使用辅助索引的时候只能取得到主键值，然后进行回表，但若是在组合索引的时候有索引存储的数据结构上就有我们想要查询到的值，那么就不用回表，直接返回。

### AddIndex

MySQL各版本，对于add Index的处理方式是不同的，主要有三种：CopyTable|Inplace|Online方式。

InnoDB的Online Add Index，首先是Inplace方式创建索引，**无需使用临时表**。在遍历聚簇索引，收集记录并插入到新索引的过程中，**原表记录可修改**。而**修改的记录保存在Row Log中**。当聚簇索引遍历完毕，并全部插入到新索引之后，重放Row Log中的记录修改，使得新索引与聚簇索引记录达到一致状态。

- 与Copy Table方式相比，Online Add Index采用的是Inplace方式，无需Copy Table，**减少了空间开销**；与此同时，Online Add Index只有在重放Row Log最后一个Block时锁表，**减少了锁表的时间**。
- 与Inplace方式相比，Online Add Index吸收了Inplace方式的优势，**却减少了锁表的时间**。

使用optimize table、analyze table和alter table这三种方式重建表的区别：

## 性能优化

### 索引优化

- 索引维护：B+树为了维护索引有序性,在插入新值的时候需要做必要的维护

- 页分裂|回表

- 独立的列

- 前缀索引

  建立一个区分度很高的前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。

  前缀索引的联合索引即使已经包含了相关信息，还是会回表。

  > **长的字段，想做索引我们怎么去优化他呢？**
  >
  > 只要区分度过高，都可以，那我们可以采用倒序，或者删减字符串这样的情况去建立我们自己的区分度，不过大家需要注意的是，调用函数也是一次开销。

- 唯一索引和普通索引的选择难题

  如果能够将更新操作先记录在change buffer，减少读磁盘，且数据读入内存是需要占用Buffer pool的即能避免占用内存，提高内存利用率。

  **唯一索引的更新就不能使用change buffer**，实际上也只有**普通索引可以使用**。

  > change buffer：当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个**数据页还没有在内存中的话**，在不影响数据一致性的前提下，InooDB会将这些**更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页**了。
  >
  > 在下次查询需要访问这个数据页的时候，将数据页读入内存，然后**执行change buffer中与这个页有关的操作**，通过这种方式就能保证这个数据逻辑的正确性。
  >
  > change buffer用的是buffer pool里的内存，**因此不能无限增大**，change buffer的大小，可以通过参数**innodb_change_buffer_max_size来动态设置**，这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。
  >
  > change buffer在**内存中有拷贝，也会被写入到磁盘上**。
  >
  > **redo log主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的是随机读磁盘的IO消耗。**
  >
  > 适合使用场景：**写多读少类型**即类似于账单类、日志类的系统。
  >
  > ![image-20201109162604221](http://img.zhengyua.cn/img/20201109162604.png)

  

- 避免回表过程：

  - 覆盖索引

    索引已经覆盖了查询需求；

  - 最左前缀原则（使用联合索引）

    字段顺序排序，利用索引来加速检索；

    > 联合索引的创建原则：考虑其索引的复用能力

  - 索引下推

    对索引中包含的字段先做判断，直接过滤掉不满足条件记录。

> 不论是删除主键还是创建主键，都会将整个表重建。

### 条件字段

- 字段使用函数计算则不会使用索引；

对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能，需要注意的是，优化器并不是要放弃使用这个索引。

- 字段的隐式类型转换则不会使用索引；

- 隐式字符编码转换则不会使用索引；

### 查询性能优化

**使用 explain 分析 select 查询语句**：

> explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。

**select_type**：

常用的有 SIMPLE 简单查询，UNION 联合查询，SUBQUERY 子查询等。

**table**：

要查询的表

**possible_keys**：

> The possible indexes to choose

可选择的索引

**key**：

> The index actually chosen

实际使用的索引

**rows**：

> Estimate of rows to be examined

扫描的行数

**type**：

> 索引查询类型，经常用到的索引查询类型：
>
> - const：使用主键或者唯一索引进行查询的时候只有一行匹配；
> - ref：使用非唯一索引；
> - range：使用主键、单个字段的辅助索引、多个字段的辅助索引的最后一个字段进行范围查询；
> - index：和all的区别是扫描的是索引树；
> - all：扫描全表。

- system

  触发条件：表只有一行，这是一个 const type 的特殊情况

- const

  触发条件：在使用主键或者唯一索引进行查询的时候只有一行匹配。

- eq_ref

  触发条件：在进行联接查询的，使用主键或者唯一索引并且只匹配到一行记录的时候。

- ref

  触发条件：使用非唯一索引。

- range

  触发条件：只有在使用主键、单个字段的辅助索引、多个字段的辅助索引的最后一个字段进行范围查询才是 range。

- index

  触发条件：只扫描索引树

- all

  触发条件：全表扫描，不走索引

### 优化数据访问

- 减少请求的数据量
  - 只返回**必要的列**：最好不要使用 SELECT * 语句。
  - 只返回**必要的行**：使用 LIMIT 语句来限制返回的数据。
  - **缓存重复查询的数据**：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。
- 减少服务器端扫描的行数
  - 最有效的方式就是使用索引来覆盖索引

### 重构查询方式

- 切分大查询

  一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。

- 分解大连接查询

  将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：

  - **让缓存更高效**。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用；
  - **分解成多个单表查询**，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询；
  - **减少锁竞争**；
  - 在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到**高性能和可伸缩**；
  - 查询本身效率也可能会有所提升。

### 分库分表数据切分

**水平切分（Sharding）**：将同一个表中的记录拆分到多个结构相同的表中。

> 当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力。

**垂直切分**：将一张表按列分成多个表。

> 通过按列的关系紧密程度进行切分，也可以按照使用程度切分。

**Sharding策略**：

- 哈希取模；
- 范围：可以是ID范围也可以是时间范围；
- 映射表：使用单独的一个数据库来存储映射关系；

**Sharding存在的问题**：

- 事务问题：使用分布式事务来解决；
- 连接：可以将原来的链接分解成多个单标查询；
- 唯一性：使用全局唯一ID|为每个分片指定一个ID范围|分布式ID生成器（Snowflake算法）。

### 数据库调优

- 排除缓存干扰
- Explain

## 其他性能优化

### 连接池

- 需要一个小连接池和一个充满了等待连接的线程的队列

你需要一个10来个连接的小连接池，然后让剩下的业务线程都在队列里等待。连接池中的连接数量应该等于你的数据库能够有效同时进行的查询任务数（通常不会高于2*CPU核心数）。

### 删表空间回收问题

**数据库表的空间回收问题**：简单地删除表数据达不到表空间回收的效果。

**表数据既可以存在共享表空间里，也可以是单独的文件。**

> 这个行为是由参数innodb_file_per_table控制的，若为ON则为文件，反之则为共享表空间。
>
> 其默认值为ON。若为共享表空间即会造成回收了表空间也不会回收此共享空间。

表中的数据被删除了，但是表空间却没有被回收？

- 数据页复用：从B+树摘掉后，可以复用到任何位置；
- 记录复用：只限于符合范围条件的数据，即复用范围有限；

如果使用delete命令删除整个表的空间：所有的数据页都会被**标记为可复用。但是磁盘上，文件不会变小**。

**实际上，**不止是删除数据会造成空洞，插入数据也会。

- 如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成**索引的数据页分裂。**
- 更新索引上的值，可以理解为**删除一个旧的值，再插入一个新值**。不难理解，这也是会造成空洞的。

### Count(*)

按照效率排序的话，**count(字段)<count(主键id)<count(1)≈count(\*)**，所以建议尽量使用count(*)。

因为更新计数表涉及到行锁的竞争，先插入再更新能最大程度地减少了事务之间的锁等待，提升了并发度。**从并发系统性能的角度考虑，应该先插入操作记录，再更新计数表。**

### OrderBy

- 如果MySQL实在是担心**排序内存太小，会影响排序效率，才会采用rowid排序算法**，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。
- 如果MySQL认为**内存足够大，会优先选择全字段排序**，把需要的字段都放到sort_buffer中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。

这也就体现了MySQL的一个设计思想：**如果内存够，就要多利用内存，尽量减少磁盘访问。**

## 锁

> 锁是数据库系统区别于文件系统的一个关键特性。锁机制用于管理对共享资源的并发访问。

### 普通锁类型

- 共享锁（S Lock）：允许事务读一行数据；
- 排他锁（X Lock）：允许事务删除或者更新一行数据；
- 意向共享锁（IS Lock）：事务想要获得一张表中某几行锁；
- 意向排它锁：事务想要获得一张表中某几行的排它锁。

### 特殊锁类型

- 全局锁：整个数据库实例加锁；

  > 加全局读锁的方法：
  >
  > - `Flush tables with read lock`简称**FTWRL**；
  > - （只适用于事务引擎）mysqldump使用参数single-transaction；
  > - 修改为全局可读；
  >
  > 使用FTWRL会让整个库处于读状态,之后其他线程的**数据更新语句|数据定义语句|更新类事务的提交语句**就会被阻塞。
  >
  > 一致性读前提是要引擎支持这个隔离级别即可重复读的隔离级别，若引擎不支持事务，那么就需要FTWRL命令。
  >
  > 全局可读锁造成的影响面更大，且在异常处理机制上不会释放全局锁导致数据库长时间不可写状态。

- 表级锁：表锁|元数据锁（MDL）

  > 语法**lock tables .... read/write**，可以用**unlock tables**主动释放锁，也可以在客户端断开的时候自动释放。
  >
  > MDL不需要**显示使用**，在进行DML时会加MDL读锁，进行DDL时会加MDL写锁。
  >
  > Online DDL的过程是这样的：
  >
  > - 拿MDL写锁-》降级成MDL读锁-》真正做DDL-》升级成MDL写锁-》释放MDL锁。
  >
  > 事务中的MDL锁，在语句执行开始时申请，但是**语句结束后并不会马上释放，而会等到整个事务提交后再释放**。
  >
  > 安全地表加字段：
  >
  > - 解决长事务：通过Kill事务或暂停DDL；
  > - 设置等待时间：超时得不到写锁后不会阻塞后面语句即先放弃；

- 行锁：通过锁索引记录实现的，如果更新的列没建索引是会锁住整个表的。

  > 在InnoDB事务中，行锁是在**需要的时候才加上的**，但并不是不需要了就立刻释放，而是要等到**事务结束时才释放**。这个就是两阶段锁协议。
  >
  > 如果你的事务中需要锁多个行，要把**最可能造成锁冲突、最可能影响并发度的锁尽量往后放**。

### 死锁

当出现了死锁之后，一般有两种策略：

- 通过参数**innodb_lock_wait_timeout来设置超时时间**，直接让事务进行等待，直到超时；

  > InnoDB中默认为50秒；

- 发起**死锁检测**，发现死锁后就主动回滚死锁链条中的某一个事务，让其他事务得以继续执行；

  > 将参数innodb_deadlock_detect设置为on即表示开启这个逻辑

但是当出现**热点行更新导致的性能问题**,通过以上两种策略不一定能很好地解决,一般有以下三种方法：

- **采取**如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉；
- **控制并发度**，且这个并发控制要做在数据库服务端；
- 考虑通过将一行改成逻辑上的多行来减少锁冲突；

### MVCC

多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。

> 基础概念：
>
> - 版本号：系统版本号|事务版本号；
> - 隐藏的列：MVCC 在每行记录后面都保存着两个隐藏的列，用来存储两个版本号：创建版本号|删除版本号；
> - Undolog：存储MVCC的快照并连接起来；

#### 实现过程

> 以下实现过程针对可重复读隔离级别。

- SELECT

  多个事务必须读取到同一个数据行的快照，并且这个快照是**距离现在最近的一个有效快照**。但是也有例外，如果有一个事务正在修改该数据行，那么它可以读取事务本身所做的修改，而不用和其它事务的读取结果一致。

  > 把没有对一个数据行做修改的事务称为 T，T 所要读取的数据行快照的创建版本号必须**小于等于 T 的版本号**，因为如果大于 T 的版本号，那么表示该数据行快照是其它事务的最新修改，因此不能去读取它。除此之外，T 所要读取的数据行快照的删除版本号必须是**未定义或者大于 T 的版本号**，因为如果小于等于 T 的版本号，那么表示该数据行快照是已经被删除的，不应该去读取它。

- INSERT

  将当前系统版本号作为数据行快照的创建版本号。

- DELETE

  将当前系统版本号作为数据行快照的删除版本号。

- UPDATE

  将当前系统版本号作为更新前的数据行快照的删除版本号，并将当前系统版本号作为更新后的数据行快照的创建版本号。可以理解为**先执行 DELETE 后执行 INSERT**。

#### 快照读与当前读

事务的隔离级别实际上**都是定义的当前读的级别**，MySQL为了**减少锁处理**（包括等待其它锁）的时间，**提升并发能力**，引入了快照读的概念，使得**select不用加锁**。而update、insert这些“当前读”的隔离性，就需要通过加锁来实现了。

- 快照读 (snapshot read)：对于这种读取历史数据的方式；
- 当前读 (current read)：读取数据库当前版本数据的方式。

**事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。**

在MVCC中：

- 快照读不需要进行加锁操作，因为读的快照中的数据；
- 在当前读中MVCC会对修改操作进行加锁操作从而获得最新的数据，而不会对SELECT进行加锁操作。

> 在进行 SELECT 操作时，可以强制指定进行加锁操作。
>
> ```mysql
> #以下第一个语句需要加 S 锁，第二个需要加 X 锁：
> select * from table where ? lock in share mode;
> select * from table where ? for update;
> ```

### 锁算法

**Record Lock**：

锁定个记录上的索引，而不是记录本身；

> 如果没有设置索引，InnoDB会自动在主键上创建隐藏的聚簇索引，则Record Lock依然可用。

**Gap Lock**：

锁定索引之间的间隙，但不包含索引本身。

**Next-Key Lock**：

它是Record Locks和Gap Locks的集合，不仅锁定一个记录上的索引且包含索引之间的间隙。

> 在 InnoDB 存储引擎中，**SELECT** 操作的不可重复读问题通过 **MVCC** 得到了解决，而 **UPDATE、DELETE** 的不可重复读问题通过 **Record Lock** 解决，**INSERT** 的不可重复读问题是通过 **Next-Key Lock（Record Lock + Gap Lock）**解决的。

### 锁问题

**脏读**（Dirty read）：一个事务中访问到了另外一个事务未提交的数据；

**不可重复读**（non-repeatable read）：一个事务读取同一条记录得到的结果不一致；

**幻读**（phantom read）：一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。

**丢失更新**：一个事务的更新操作会被另一个事务的更新操作所覆盖。

## 复制

### 主从复制

主要涉及三个线程：**binlog 线程、I/O 线程和 SQL 线程**。

- binlog 线程 ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。
- I/O 线程 ：负责从主服务器上读取- 二进制日志，并写入从服务器的中继日志（Relay log）。
- SQL 线程 ：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。

![image-20201109125422097](http://img.zhengyua.cn/img/20201109125422.png)

### 读写分离

主服务器处理**写操作以及实时性要求比较高**的读操作，而从服务器处理**读操作**。

读写分离能提高性能的原因在于：

- 主从服务器负责各自的读和写，极大程度**缓解了锁争用**；
- 从服务器可以使用 **MyISAM**，提升查询性能以及节约系统开销；
- 增加冗余，**提高可用性**。

读写分离常用**代理方式**来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。

![image-20201109125600271](http://img.zhengyua.cn/img/20201109125600.png)

## 关系数据库设计理论

### 函数依赖

- 记 A->B 表示 A 函数决定 B，也可以说 B 函数依赖于 A。
- 如果 {A1，A2，... ，An} 是关系的一个或多个属性的集合，该集合函数决定了关系的其它所有属性并且是最小的，那么该集合就称为键码。
- 对于 A->B，如果能找到 A 的真子集 A'，使得 A'-> B，那么 A->B 就是部分函数依赖，否则就是完全函数依赖。
- 对于 A->B，B->C，则 A->C 是一个传递函数依赖。

### 异常

不符合范式的关系，会产生很多异常，主要有以下四种异常：

- 冗余数据：例如 `学生-2` 出现了两次。
- 修改异常：修改了一个记录中的信息，但是另一个记录中相同的信息却没有被修改。
- 删除异常：删除一个信息，那么也会丢失其它信息。例如删除了 `课程-1` 需要删除第一行和第三行，那么 `学生-1` 的信息就会丢失。
- 插入异常：例如想要插入一个学生的信息，如果这个学生还没选课，那么就无法插入。

### 范式

范式理论是为了解决以上提到四种异常。

  ![image-20200430105216340](http://img.zhengyua.cn/663421ade591b10c811064e584621b822f3a2386)

高级别范式的依赖于低级别的范式，1NF 是最低级别的范式。

- 第一范式1NF：属性不可分；

- 第二范式2NF：每个非主属性完全函数依赖于键码；

  ![image-20200426114735162](http://img.zhengyua.cn/00282bf940f0734c6cf67151262e585add072ed9)

  ![image-20200426115126138](http://img.zhengyua.cn/e317c15c843feb8cb5231c065a169ecdc97a3b65)

- 第三范式3NF：非主属性不传递函数依赖于键码；

  ![image-20200430103301731](http://img.zhengyua.cn/d70506e6c665574854e8e2ccb341d7a3c2394a36)

  ![image-20200430103648697](http://img.zhengyua.cn/ad7a7a6aea4ec035b367c3b1d3f9fa1d66d44a3f)

- BC范式（BCNF）：BCNF是修正的第三范式，有时也称为扩展的第三范式。

  ![image-20200430104525570](http://img.zhengyua.cn/a593806d284751be22fcba09d0df9b76fb4fd366)

> **ER图**：Entity-Relationship，有三个组成部分：实体、属性、联系。
>
> 实体的三种**联系**：包含一对一，一对多，多对多三种。
>
> ![image-20201109130400927](http://img.zhengyua.cn/img/20201109130401.png)
>
> ![image-20201109130422884](http://img.zhengyua.cn/img/20201109130422.png)

