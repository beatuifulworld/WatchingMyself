> 本文借鉴大量博客和笔记

[TOC] 

# Start

## 并发与多线程



## 分布式

### MQ

#### 使用场景

MQ的作用：**削峰填谷**。

考虑到操作同步处理，调用链太长影响接口性能，其次就是分布式事务问题较难解决，对实时一致性要求不高的请求可以用mq进行异步处理，而异步带来的不一致问题，可以通过`job`去重试保证接口调用成功，且一般有核对平台作为兜底的处理方案。

#### MQ的选型

- 性能；
- 开发语言；
- 高并发业务场景需要的分布式架构；
- 功能全面，不同的业务场景有顺序消息、事务消息等。

![image-20201209215524435](http://img.zhengyua.cn/img/20201209215524.png)

#### 消息可靠性保证

消息丢失可能发生在生产者丢失发送消息、MQ本身丢失消息、消费者丢失消息三个方面。

##### 生产者丢失

可能发生的原因有：

- 程序发送抛出异常了没有重试处理；
- 发送过程成功但因为网络闪断MQ没收到；

异步发送分为两个方式：**异步有回调和异步无回调**。

无回调的方式，生产者发送完后不管结果可能就会造成消息丢失，而通过**异步发送+回调通知+本地消息表**的形式我们就可以做出一个解决方案。

以下单的场景举例：

1. **下单后先保存本地数据和MQ消息表，这时候消息的状态是发送中，如果本地事务失败，那么下单失败，事务回滚。**
2. **下单成功，直接返回客户端成功，异步发送MQ消息**
3. **MQ回调通知消息发送结果，对应更新数据库MQ发送状态**
4. **JOB轮询超过一定时间（时间根据业务配置）还未发送成功的消息去重试**
5. **在监控平台配置或者JOB程序处理超过一定次数一直发送不成功的消息，告警，人工介入。**

一般而言，对于大部分场景来说**异步回调的形式**就可以了，只有那种需要完全保证不能丢失消息的场景我们做一套完整的解决方案。

##### MQ丢失

可能的原因：生产者保证消息发送到MQ，而MQ收到消息后还在内存中，这时候宕机了又**没来得及同步给从节点**，就有可能导致消息丢失。

比如RocketMQ：RocketMQ分为**同步刷盘和异步刷盘**两种方式，默认的是异步刷盘，就有可能导致消息还未刷到硬盘上就丢失了，可以通过设置为**同步刷盘的方式来保证消息可靠性**，这样即使MQ挂了，恢复的时候也可以从磁盘中去恢复消息。

##### 消费者丢失

可能的原因：消费者刚收到消息，此时服务器宕机，MQ认为消费者已经消费，不会重复发送消息，消息丢失。

RocketMQ默认是需要消费者回复ack确认，而kafka需要手动开启配置关闭自动offset。

![image-20201209220304434](http://img.zhengyua.cn/img/20201209220304.png)

#### 消费失败导致的消息积压处理

因为考虑到时消费者消费一直出错的问题，可以从以下几个角度来考虑：

1. 消费者出错，肯定是程序或者其他问题导致的，如果容易修复，先把问题修复，让**consumer恢复正常消费**；
2. 如果时间来不及处理很麻烦，**做转发处理，写一个临时的consumer消费方案**，先把消息消费，然后再**转发到一个新的topic和MQ资源**，这个新的topic的机器资源单独申请，要能承载住当前积压的消息；
3. 处理完积压数据后，修复consumer，去**消费新的MQ和现有的MQ数据，新MQ消费完成后恢复原状**。

#### 消息积压到磁盘上限被删除

最初，我们**发送的消息记录是落库保存了的，而转发发送的数据也保存了**，那么我们就可以通过这部分数据来找到丢失的那部分数据，再单独跑个脚本重发就可以了。如果转发的程序没有落库，那就和消费方的记录去做对比，只是过程会更艰难一点。

#### RocketMQ实现原理

RocketMQ由以下组件组成：

- NameServer注册中心集群；
- Producer生产者集群；
- Consumer消费者集群；
- 若干Broker（RocketMQ进程）。

它的架构原理是这样的：

1. Broker在启动的时候去向所有的**NameServer注册**，并**保持长连接**，**每30s发送一次心跳**；
2. Producer在发送消息的时候**从NameServer获取Broker服务器地址**，根据负载均衡算法选择一台服务器来发送消息；
3. Conusmer消费消息的时候同样**从NameServer获取Broker地址**，**然后主动拉取消息来消费**。

![image-20201209220849191](http://img.zhengyua.cn/img/20201209220849.png)

#### RocketMQ不使用Zookeeper作为注册中心

我认为有以下几个点是不使用zookeeper的原因：

1. **根据CAP理论**，同时最多只能满足两个点，而zookeeper满足的是CP，也就是说**zookeeper并不能保证服务的可用性**，zookeeper在**选举期间**整个集群都处于不可用的状态，而这对于一个注册中心来说肯定是不能接受的，作为**服务发现来说就应该是为可用性而设计**。
2. **基于性能的考虑**，NameServer本身实现非常**轻量**且可以通过增加机器的方式**水平扩展**以此增加集群的抗压能力，而**zookeeper的写是不可扩展的**，而zookeeper要解决这个问题只能通过**划分领域**，划分多个zookeeper集群来解决，首先**操作复杂**，其次这样还是又**违反了CAP中的A的设计**，导致服务之间是不连通的。
3. **持久化机制**来带的问题，zookeeper 的 **ZAB 协议**对每一个写请求，会在每个 zookeeper 节点上**保持写一个事务日志**，同时再加上**定期的将内存数据镜像（snapshot）到磁盘**来保证数据的一致性和持久性，而对于一个简单的服务发现的场景来说，这其实没有太大的必要，实现方案过重了且**本身存储的数据应该是高度定制化的**。
4. 消息发送应该**弱依赖注册中心**，而RocketMQ的设计理念也正是基于此，生产者在第一次发送消息的时候**从NameServer获取到Broker地址后缓存到本地**，如果NameServer整个集群不可用，**短时间内对于生产者和消费者并不会产生太大影响**。

#### Broker保存数据

RocketMQ主要的存储文件：

- `commitlog`文件；
- `consumequeue`文件；
- `indexfile`文件。

Broker在收到消息之后将**消息保存到commitlog的文件当中**，同时在分布式的存储当中，每个broker都会保存部分topic的数据且每个topic对应的messagequeue下都会**生成consumequeue文件用于保存commitlog的物理位置偏移量offset**，**indexfile中会保存key和offset的对应关系**。

![image-20201209221657792](http://img.zhengyua.cn/img/20201209221657.png)

CommitLog文件保存于`${Rocket_Home}/store/commitlog`目录中，从图中我们可以明显看出来文件名的偏移量，每个文件默认1G，写满后自动生成一个新的文件。

![image-20201209221722635](http://img.zhengyua.cn/img/20201209221722.png)

由于同一个topic的消息**并不是连续的存储在commitlog**中，消费者如果直接从commitlog获取消息效率非常低。

所以通过**consumequeue保存commitlog中消息的偏移量的物理地址**，这样消费者在消费的时候先从consumequeue中**根据偏移量定位到具体的commitlog物理文件**，**然后根据一定的规则（offset和文件大小取模）在commitlog中快速定位**。

![image-20201209221747458](http://img.zhengyua.cn/img/20201209221747.png)

#### Master和Slave之间如何同步数据

消息在master和slave之间的同步是根据raft协议来进行的：

1. 在broker收到消息后，会被标记为`uncommitted`状态；
2. 然后会把消息发送给所有的slave；
3. slave在收到消息之后返回ack响应给master；
4. master在收到超过半数的ack之后，把消息标记为`committed`；
5. 发送`committed`消息给所有slave，slave也修改状态为`committed`。

#### RocketMQ速度快的原因

是因为使用了**顺序存储**、**Page Cache**和**异步刷盘**。

1. 写入commitlog的时候是顺序写入的，这样比随机写入的性能就会提高很多；
2. 写入commitlog的时候并不是直接写入磁盘，而是先写入操作系统的PageCache；
3. 最后由操作系统异步将缓存中的数据刷到磁盘。

#### 如何实现事务和半事务

事务消息就是MQ提供的类似XA的分布式事务能力，**通过事务消息可以达到分布式事务的最终一致性**。

半事务消息就是MQ收到了生产者的消息，**但是没有收到二次确认，不能投递的消息**。

实现原理如下：

1. 生产者先发送一条半事务消息到MQ；
2. MQ收到消息后返回ack确认；
3. 生产者开始执行本地事务；
4. 如果事务执行成功发送commit到MQ，失败发送rollback；
5. 如果MQ长时间未收到生产者的二次确认commit或者rollback，MQ对生产者发起消息回查；
6. 生产者查询事务执行最终状态；
7. 根据查询事务状态再次提交二次确认；
8. 最后如果MQ收到二次确认commit，就可以把消息投递给消费者，反之如果是rollback，消息会保存下来并且在3天后被删除。

### RPC



### Etcd

etcd 是 CoreOS 团队于 2013 年 6 月发起的开源项目，它的目标是构建一个高可用的分布式键值(key-value)数据库。

#### 特点

- 简单：安装配置简单，而且提供了HTTP API进行交互，使用简单；
- 键值对存储：将数据存储在分层组织的目录中，如同在标准文件系统中；
- 监测变更：监测特定的键或目录以进行更改，并对值的更改做出反应；
- 安全：支持SSL证书验证；
- 快速：根据官方提供的benchmark数据，单实例支持每秒2k+读操作；
- 可靠：采用raft算法，实现分布式系统数据的可用性和一致性；

采用 Go 语言编写，具有出色的跨平台支持，很小的二进制文件和强大的社区。

机器之间的通信通过 Raft 算法处理。高度一致的分布式键值存储，提供一种可靠的方式来存储需要由分布式系统或机器集群访问的数据。优雅地处理网络分区期间的leader选举，以应对机器的故障，即使在leader节点发生故障时。

#### 使用场景

> A highly-available key value store for shared configuration and service discovery.
> 一个用于配置共享和服务发现的键值存储系统。
>
> 归根结底，etcd 是一个**键值存储**的组件，其他的应用都是基于其键值存储的功能展开。

##### 键值对存储

etcd 的存储有如下特点：

- 采用**kv型数据存储**，一般情况下比关系型数据库快；
- 支持**动态存储(内存)以及静态存储(磁盘)**；
- **分布式存储**，可集成为多节点集群；
- 存储方式，采用**类似目录结构**：
    - 只有叶子节点才能真正存储数据，相当于文件；
    - 叶子节点的父节点一定是目录，目录不能存储数据。

**etcd leader的延迟是要跟踪的最重要的指标**，并且内置仪表板具有专用于此的视图。在我们的测试中，**严重的延迟会在群集内造成不稳定**，因为 Raft 的速度仅与大多数机器中最慢的机器一样快。我们可以通过适当地调整群集来缓解此问题。

##### 服务注册与发现

服务注册与发现(Service Discovery)要解决的是分布式系统中最常见的问题之一，即**在同一个分布式集群中的进程或服务如何才能找到对方并建立连接**。从本质上说，服务发现就是要了解集群中是否**有进程在监听UDP或者TCP端口**，并且通过名字就可以进行查找和链接。

- 基于 Raft 算法的**强一致性、高可用的服务存储目录**；
- 通过`key TTL`实现**注册服务和服务健康状况的机制**，定时保持服务的心跳以达到监控健康状态的效果；
- 一种**查找和连接服务的机制**。通过在 etcd 指定的主题下注册的服务业能在对应的主题下查找到。为了确保连接，我们可以在每个服务机器上都**部署一个 Proxy 模式的 etcd**，这样就可以确保访问 etcd 集群的服务都能够**互相连接**。

> etcd2 中引入的 etcd/raft 库，是**目前最稳定、功能丰富的开源一致性协议之一**。作为 etcd、TiKV、CockcorachDB、Dgraph 等知名分布式数据库的核心数据复制引擎，etcd/raft 驱动了超过十万个集群，是被**最为广泛采用一致性协议实现之一**。etcd3 中引入的**多版本控制、事务等功能**，大大的简化了分布式应用的开发流程，提高了效率和稳定性。

##### 消息发布与订阅

在分布式系统中，最适用的一种组件间通信方式就是**消息发布与订阅**。即构建一个**配置共享中心**，数据提供者在这个配置中心发布消息，而消息使用者则订阅他们关心的主题，一旦主题有消息发布，就会实时通知订阅者。通过这种方式可以做到**分布式系统配置的集中式管理与动态更新**。

**分布式搜索服务**中，**索引的元信息和服务器集群机器的节点状态**存放在etcd中，供各个客户端订阅使用。使用etcd的key TTL功能可以确保机器状态是实时更新的。

**分布式日志收集系统**。这个系统的核心工作是收集分布在不同机器的日志。收集器通常是按照应用（或主题）来分配收集任务单元，因此可以在etcd上创建一个以应用（主题）命名的目录P，并将这个应用（主题相关）的所有机器ip，以子目录的形式存储到目录P上，然后**设置一个 etcd 递归的Watcher，递归式的监控应用（主题）目录下所有信息的变动**。这样就实现了机器IP（消息）变动的时候，能够**实时通知到收集器调整任务分配**。

系统中信息**需要动态自动获取与人工干预修改信息请求内容的情况**。通常是**暴露出接口**，例如JMX接口，来获取一些运行时的信息。引入etcd之后，就不用自己实现一套方案了，只要将这些信息存放到指定的etcd目录中即可，**etcd的这些目录就可以通过HTTP的接口在外部访问**。

##### 分布式通知与协调

etcd中的Watcher机制，**通过注册与异步通知机制，实现分布式环境下不同系统之间的通知与协调**，从而对数据变更做到实时处理。

实现方式通常是这样：不同系统都在etcd上**对同一个目录进行注册**，**同时设置Watcher观测该目录的变化（如果对子目录的变化也有需要，可以设置递归模式）**，当某个系统更新了etcd的目录，那么设置了Watcher的系统就会收到通知，并作出相应处理。

通过etcd进行**低耦合的心跳检测**。检测系统和被检测系统通过etcd上**某个目录关联而非直接关联起来**，这样可以大大减少系统的耦合性。

![image-20201209233246936](http://img.zhengyua.cn/img/20201209233247.png)

**通过etcd完成系统调度**。某系统有控制台和推送系统两部分组成，控制台的职责是控制推送系统进行相应的推送工作，通过修改etcd上某些目录节点的状态，然后etcd就把这些变化通知给注册了Watcher的推送系统客户端，推送系统再作出相应的推送任务。

**通过etcd完成工作汇报**。大部分类似的任务分发系统，子任务启动后，到etcd来**注册一个临时工作目录**，并且定时将自己的进度进行汇报（将进度写入到这个临时目录）达到**任务管理者就能够实时知道任务进度**。

##### 分布式锁

当在分布式系统中，数据只有一份（或有限制），此时需要利用**锁的技术控制某一时刻修改数据的进程数**。与单机模式下的锁不仅需要保证进程可见，分布式环境下还需要考虑**进程与锁之间的网络问题**。

分布式锁可以**标记存在内存**，只是该内存不是某个远程分配的内存而是**公共内存**如Redis、Memcache。至于利用数据库、文件等做锁与单机的实现是一样的，只要**保证标记能互斥**就行。

etcd使用Raft算法**保持了数据的强一致性**，使操作存储到集群中的值必然是全局一致的，所以很容易实现分布式锁。锁服务有两种使用方式，一是保持独占，二是控制时序。

- 保持独占

  所有获取锁的用户最终只有一个可以得到。

  etcd为此提供了一套实现**分布式锁原子操作CAS（CompareAndSwap）的API**。通过设置prevExist值，可以保证在多个节点同时去创建某个目录时，只有一个成功即获得唯一锁。

- 控制时序

  所有想要获得锁的用户都会被安排执行，但是**获得锁的顺序也是全局唯一的，同时决定了执行顺序**。

  etcd为此也**提供了一套API（自动创建有序键）**，对一个目录建值时指定为POST动作，这样etcd会自动在目录下生成一个当前最大的值为键，存储这个新的值（客户端编号）。**同时还可以使用API按顺序列出所有当前目录下的键值**。此时这些键的值就是客户端的时序，而这些键中存储的值可以是代表客户端的编号。





- etcd是什么？有什么优势
- raft选主逻辑
- 日志复制
- 脑裂问题
- etcd的watch机制
- etcd如何实现配置下发和服务发现
- etcd对于偶数机器的集群的选主处理
- 选主实现逻辑

## Golang

### 语言优势



### 语言基础

#### 数组与切片

##### 数组

- 数组类型的长度是固定的数组类型长度，必须在类型声明的时候给出，即**数组的长度是其类型的一部分**，组成分别为`Elem`元素类型和`Bound`长度。
- 语句转换：
    1. 当元素数量**小于等于4时**，直接将数组中的元素放在**栈上**；
    2. 当元素数量**大于4时**，会将数组中的元素放置到**静态区并在运行时取出**；
- Go 语言中可以在编译期间的静态类型检查判断**数组越界**，若使用变量去访问数组或者字符串，编译器就无法提前发现错误，需要Go语言运行时阻止不合法的访问。

##### 切片

- 切片类型的长度是不固定的即可以为**动态数组**，在切片的底层数据结构中会包含一个数组，而切片就是**对底层数组的引用**，故切片类型也属于**引用类型**。
- 切片的容量不足时旧会调用`runtime.growslice`函数为**切片扩容**，扩容就是为**切片分配一块新的内存空间并将原切片的元素全部拷贝过去**，切片的扩容策略：

    1. 如果**期望容量大于当前容量的两倍**就会使用期望容量；
    2. 如果当前切片的长度**小于 1024** 就会将容量翻倍；
    3. 如果当前切片的长度**大于 1024** 就会每次增加 25% 的容量，直到新容量大于期望容量；

#### 参数传递

- Golang里面只有**值传递**，都是一个副本，一个拷贝；
- 在参数传递中对于**非引用类型（int、string、struct等）**，函数中无法修改原本内容数据；对于**引用类型（指针、map、slice、chan等）**，可以修改原本内容数据，但实际上也是**拷贝了引用类型的参数**，让函数中参数新的内存地址指向了原本内容数据的内存地址，然后进行的修改也会影响到原本引用类型参数指向的内存地址的数据。

### 并发编程

#### context

- Context的主要作用就是在不同的Goroutine之间**同步请求特定的数据、取消信号以及处理请求的截止日期**。**避免对计算资源的浪费**，本质上是通过协程调度的方式。
- 正确使用`context.Context`时，当**父层执行失败时下层能够及时停掉无用的工作以减少额外资源的消耗**。
- Cntext的调用应该是**链式的**，通过`WithCancel`、`WithDeadline`、`WithTimeout`、`WithValue`派生出新的Context。当父Context被取消时其**派生的所有Context都将取消**。
- 通过`context.WithXXX`都返回新的**Context和CancelFunc**。调用CancelFunc将取消子代，移除父代对子代的引用，并停止所有定时器。未能调用CancelFunc将泄漏子代，直到父代被取消或定时器触发。
- Context在使用时需要注意：上游任务仅仅使用context通知下游任务不再需要，但不会直接干涉和中断下游任务的执行，由下游任务自行决定后续的处理操作，即**context的取消操作是无侵入的**；
- 使用原则：
    1. 不要把Context放在结构体中，要以参数的方式传递；
    2. 以Context作为参数的函数方法，应该把Context作为第一个参数，放在第一位；
    3. 给一个函数方法传递Context时不要传递`nil`，默认应该为`context.TODO`；
    4. Context的Value相关方法应该传递必须的数据（这是一种非常差的设计）；
    5. context是**线程安全的**，因为context本身是不可以变的，因此可以放心地在多个协程中传递使用。


#### 同步原语与锁

##### sync.Mutext

互斥锁的加锁过程比较复杂，涉及自旋、信号量以及调度等概念：

- 若互斥锁处于初始化状态，就会直接通过置位`mutexLocked`加锁；
- 若互斥锁处于`mutexLocked`并且在普通模式下工作，就会进入自旋，执行30次`PAUSE`指令，消耗CPU时间等待锁的释放；
- 如果当前Goroutine等待锁的时间超过了1ms，互斥锁切换到饥饿模式；
- 互斥锁在正常情况下会通过`runtine.sync_runtime_SemacquireMutex`函数将尝试获取锁的Goroutine切换至休眠状态，等待锁的持有者唤醒当前Goroutine；
- 如果当前Goroutine是互斥锁上的最后一个等待的协程或者等待的时间小于1ms，当前Goroutine会将互斥锁切换回正常模式；

解锁过程相比较为简单：

- 当互斥锁已经被解锁时，那么就调用`sync.Mutex.Unlock`直接抛出异常；
- 当互斥锁处于饥饿模式时，会直接将锁的所有权交给队列的下一个等待者，等待者会负责`mutexLocked`标志位；
- 当互斥锁处于普通模式时，如果没有Goroutine等待锁的释放或者已经有被唤醒的Goroutine获得了锁，就会直接返回，其他情况下会`sync.runtime_Semrelease`唤醒对应的Goroutine。

##### sync.RWMutex

- 调用`sync.RWMutex.Lock`尝试获取写锁时：
    - 每次`sync.RWMutex.RUnlock`都会将`readerCount`其减一，当它归零时该Goroutine就会获得写锁；
    - 将`readerCount`减少`rwmutexMaxReaders`个数以阻塞后续的操作；
- 调用`sync.RWMutex.Unlock`释放写锁时，会优先通知所有的读操作，然后才会释放持有的互斥锁；

读写锁在互斥锁的基础上**提供了额外的更细粒度的控制，能够在读操作远远多于写操作时提升性能**。

##### sync.WaitGroup

- `sync.WaitGroup`必须在 `sync.WaitGroup.Wait`方法返回之后才能被重新使用；
- `sync.WaitGroup.Done` 只是对`sync.WaitGroup.Add`方法的简单封装，我们可以向 `sync.WaitGroup.Add`方法传入任意负数（需要保证计数器非负）快速将计数器归零以唤醒其他等待的 Goroutine；
- 可以同时有多个 Goroutine 等待当前 `sync.WaitGroup`计数器的归零，这些 Goroutine 会被同时唤醒；

##### sync.Once

使用互斥锁和`sync/atomic`包提供的方法实现了某个函数在程序运行期间只能执行一次的语义。在使用该结构体时，需注意:

- `sync.Once.Do`方法中传入的函数只会被执行一次，哪怕函数发生了`panic`；
- 两次调用`sync.Once.Do`方法传入不同的函数也只会执行第一次调用的函数。

##### sync.Cond

`sync.Cond`不是一个常用的同步机制，在遇到长时间条件无法满足时，与使用 `for {}` 进行忙碌等待相比`sync.Cond`能够让出处理器的使用权。在使用的过程中我们需要注意以下问题：

- `sync.Cond.Wait`方法在调用之前一定要使用获取互斥锁，否则会触发程序崩溃；
- `sync.Cond.Signal`方法唤醒的 Goroutine 都是队列最前面、等待最久的 Goroutine；
- `sync.Cond.Broadcast`会按照一定顺序广播通知等待的全部 Goroutine；

##### sync.Map

- `sync.Map`与`map`中加锁的区别

  当写入操作较多时，性能是无法保证的，因为每次都有可能要**遍历read复制到dirty中**；

  当读多写少时，read是atomic.Value类型，读取时利用了atomic.Value.Load实现了原子操作，**没有用到锁，性能有所提升**。

- `read.amended`

  `amended`理解为备份标记，从read中遍历数据，复制到dirty中相当完成备份，`amended`为true，反之则为false。

- `read`和`dirty`之间的关系

  read为缓存，当缓存命中失败次数过多，会从dirty中复制数据到read中，如果dirty不为空，那么dirty的数据大于等于read。

  每次dirty创建时，都是从read中读取未被标记删除的数据复制到dirty中，之后dirty中的数据只会多于read，所以在从dirty中复制数据到read中时，只是会丢失已被标记删除的数据，而不会丢失实际数据。

#### Goroutine

- goroutine是一个轻量级的执行线程，较于线程管理消耗的资源相对更少。
- goroutine是Golang中**最基本的执行单元**，每个Golang程序至少有一个主goroutine，即程序启动时自动创建。
- goroutine协程的基本实现原理就是golang**利用并封装了操作系统的异步I/O模型函数**，如linux的epoll、select和windows的iocp、envent等。

##### 进程、线程和协程

- 进程、线程（内核级线程）和协程（用户级线程）之间概念的区别

  对于进程、线程，都是由**内核进行调度**，有CPU时间片的概念，进行**抢占式调度**。

  对于协程，对**内核透明**即系统并不知道协程的存在，完全由用户自己的程序进行调度，通常只能**协作式调度**（因很难做到像强制的CPU控制权切换线程，需要将控制权转让出去，其他协程才能被执行到），**避免了上下文切换的额外耗费**，兼顾了多线程的优点，简化了高并发程序的复杂。

- goroutine和协程区别

  本质上，goroutine就是协程，不同的是golang**在runtime、系统调用等多方面对goroutine调度进行了封装和处理**，goroutine的调度让golang从语言层面支持了协程。

- 内存消耗：goroutine2KB，线程8MB；

  切换调度：线程涉及模式切换、16个寄存器、PC、SP等寄存器的刷新，goroutine只有三个寄存器（PC、SP、DX）的值修改。

##### 设计原理

- 单线程调度器-》多线程调度器-》任务窃取调度器-》抢占式调度器-》非均匀内存访问调度器

##### 数据结构

![image-20201207111752066](http://img.zhengyua.cn/img/20201207111752.png)

- G：表示**Goroutine**，是一个待执行的任务；
- M：表示**操作系统的线程**，由操作系统的调度和管理；
- P：表示**处理器**，可以被看做**运行在线程上的本地调度器**；

###### G

- Go语言在用户态提供的线程，作为一种**粒度更细的资源调度单元**，且在调度时占用了**更小的内存空间**，也**降低了上下文切换的开销**。

![image-20201207112208812](http://img.zhengyua.cn/img/20201207112209.png)

- Goroutine的状态可分为**等待中、运行中、可运行**：
    - 等待中：Goroutine 正在等待某些条件满足，例如：系统调用结束等，包括 `_Gwaiting`、`_Gsyscall` 和 `_Gpreempted` 几个状态；
    - 可运行：Goroutine 已经准备就绪，可以在线程运行，如果当前程序中有非常多的 Goroutine，每个 Goroutine 就可能会等待更多的时间，即 `_Grunnable`；
    - 运行中：Goroutine 正在某个线程上运行，即 `_Grunning`；

###### M

- M是操作系统线程，调度器**最多可以创建10000个线程**，但其中大多数线程都不会执行用户代码（可能陷入系统调用），最多只会有`GOMAXPROCS`个活跃线程能够正常运行；
- 操作系统线程唯一关心的两个 Goroutine：`g0`（持有调度栈的Goroutine）、`curg`（当前线程上运行的用户Goroutine）；

###### P

- 是线程和Goroutine的中间层，**提供线程需要的上下文环境，也会负责调度线程上的等待队列**，通过处理器P的调度，每一个内核线程能够执行多个Goroutine，它能在Goroutine进行一些**I/O操作时及时切换**，提高线程的利用率；

##### GPM模型

在Go中，线程是运行Goroutine的实体，调度器的功能是把**可运行的Goroutine分配到工作线程上**。

![image-20201207132743540](http://img.zhengyua.cn/img/20201207132743.png)

- 全局队列（Gloab Queue）：存放等待运行的G；
- P的本地队列：同全局队列类似，存放的也是等待运行的G，存的数量有限，不超过256个。
- P列表：所有的P都在程序启动时创建，并保存在数组中，最多有`GOMAXPROCS`（可配置）个。
- M：线程想运行任务就得获取P，从P的本地队列中获取G，P队列为空时M会尝试从全局队列拿一批G放到P的本地队列中，或从其他P的本地队列偷一般放到自己P的本地队列。M运行G后，G执行之后，M会从P获取下一个G，不断重复下去。

###### P和M的个数问题

- P：在程序执行的任意时刻都只有`$GOMAXPROCS`个Goroutine在同时运行。
- M：`runtime/debug`中的SetMaxThreads函数，设置M的最大数量，或者一个M阻塞了会创建新的M。

###### P和M的创建时机

- P：在确定了P的最大数量n后，运行时系统会根据这个数量创建n个P。
- M：没有足够的M来关联P并运行其中可运行的G。

###### M0和G0

- M0

  `M0`是启动程序后的编号为0的主线程，这个M对应的实例会在全局变量runtime.m0中，不需要在heap上分配，M0负责执行初始化操作和启动第一个G， 在之后M0就和其他的M一样了。

- G0

  `G0`是每次启动一个M都会第一个创建的gourtine，G0仅用于负责调度的G，G0不指向任何可执行的函数, 每个M都会有一个自己的G0。在调度或系统调用时会使用G0的栈空间, 全局变量的G0是M0的G0。

##### 调度器的设计策略

- 复用线程

    - `work stealing`机制

      当本线程无可运行的G时，尝试从其他线程绑定的P偷取G，而不是销毁线程。

    - `hand off`机制

      当本线程因为G进行系统调用阻塞时，线程释放绑定的P，把P转移给其他空闲的线程执行。

- 并行利用

  最多有`GOMAXPROCS`个线程分布在多个CPU上同时运行。

- 抢占

  在coroutine中要等待一个协程主动让出CPU去执行下一个协程，在Go中一个Goroutine最多占用CPU10ms，防止其他Goroutine被饿死。

- 全局G队列

  在新的调度器中依然有全局G队列，但功能已经被弱化了，当M执行work stealing从其他P偷不到G时，它可以从全局G队列获取G。

##### Helloworld的过程

1. runtime创建最初的线程是M0和G0，并把2者关联。
2. 调度器初始化：初始化M0、栈、垃圾回收以及创建和初始化由GOMAXPROCS个P构成的P列表。
3. main函数是`main.main`，`runtime`中也有一个main函数——`runtime.main`，代码经过编译后，`runtime.main`会调用`main.main`，程序启动时会为`runtime.main`创建Goroutine，称之为`main Goroutine`，然后把该Goroutine加入到P的本地队列；
4. 启动M0，M0已经绑定了P，从P的本地队列中获取G，获取到`main Groutine`。
5. G拥有栈，M根据G中的栈信息和调度信息设置运行环境。
6. M运行G。
7. G退出，再次回到M获取可运行的G，这样重复直到`main.main`退出，`runtime.main`执行Defer和Panic处理，或调用`runtime.exit`退出程序。

##### Goroutine调度过程

![image-20201207132539394](http://img.zhengyua.cn/img/20201207132539.png)

1. 通过`go func()`创建一个Goroutine，会有两个存储G的队列，一个是局部调度器P的本地队列、一个全局G队列。新创建的G会优先保存在P的本地队列，若P的本地队列已满就会保存在全局队列中。
2. G只能运行在M中，一个M必须持有一个P，M与P为1:1关系。M会从P的本地队列中弹出一个可执行状态的G来执行，如果P的本地队列为空，就会向其他的MP组合中偷取一个可执行状态的G来执行。
3. 一个M调度G执行的过程是一个循环机制。
4. 当M执行某一个G时发生`syscall`或者其余阻塞操作，M会阻塞，若当前有G在执行，`runtime`会把这个M从P中摘除(detach)，然后再创建一个新的操作系统的线程（若有空闲的线程就可用就复用空闲线程）来服务这个P。
5. 当M系统调用结束的时候该G会尝试获取一个空闲的P执行，并放到该P的本地队列中。若获取不到P，那么这个线程M就会变成休眠状态，加入到空闲线程中，然后这个G也会放入到全局队列中。

> https://mp.weixin.qq.com/s/SEPP56sr16bep4C_S0TLgA

#### channel

##### 设计原理

> Share memory by communicating, don't communicate by sharing memory.
> 通过通信共享内存，而不是通过共享内存而通信。

- 收发操作：先入先出
    - 先从Channel读取数据的Goroutine会先接收到数据；
    - 先向Channel发送数据的Goroutine会得到先发送数据的权利；
- 从某种程度来说，Channel是一个用于同步和通信的有锁队列；
- channel用于并发控制以及goroutine的通信。

##### 数据结构

```go

type hchan struct {
   // chan里元素数量
   qcount   uint
   // chan维护的数组的长度
   dataqsiz uint
   // 维护的数组的指针
   buf      unsafe.Pointer
   // chan中元素大小
   elemsize uint16
   // chan是否被关闭的标志
   closed   uint32
   // chan 中元素类型
   elemtype *_type
   // 已发送元素在循环数组中的索引
   sendx    uint
   // 已接收元素在循环数组中的索引
   recvx    uint
   // 等待接收的goroutine队列
   recvq    waitq
   // 等待发送的goroutine队列
   sendq    waitq
   // 保证对chan的读写是原子操作
   lock mutex
}
```

![image-20201206210947807](http://img.zhengyua.cn/img/20201206210948.png)

##### 具体操作

通过Channel传递消息就是值的拷贝，对于有缓存的Channel先把发送方G的值拷贝到自己维护的数组，再拷贝到接收G，而非缓冲型的Channel则直接从发送栈数据拷贝到接收栈空间。

- 创建通道

    - 若当前不存在缓冲区，则会为`runtime.hchan`分配一段内存空间；
    - 若当前存储的类型不是指针，则会为当前的Channel和底层的数组分配到连续的内存空间；
    - 在默认情况下会单独为`runtime.hchan`和缓冲区分配内存；

- 发送数据

    1. 若当前Channel的`recvq`上存在已经被阻塞的Goroutine，那么会直接将数据发送给当前的Goroutine上，并将其设置成下一个运行的Goroutine；
    2. 若Channel存在缓冲区且其中还有空闲的容量，将数据存储到当前缓冲区`sendx`所在的位置上；
    3. 若不满足上面情况，就会创建`runtime.sudog`结构并将其加入Channel的`sendq`队列中，当前Goroutine也会陷入阻塞等待Gwaiting状态（既不在全局运行队列也不在某个P的运行队列中）其他的Goroutine从Channel接收数据；

  该过程中包含几个会触发Goroutine调度的时机：

    1. 发送数据时发现Channel上存在等待接收数据的Goroutine，立即设置处理器的`runnext`属性，但是并不会立刻触发调度；
    2. 发送数据时并没有找到接收方并且缓冲区已经满了，这时就会将自己加入Channel的`sendq`队列并调用`runtime.goparkunlock`触发Goroutine的调度让出处理器的使用权；

- 接收数据

    1. 若Channel为空则直接调用`runtime.gopark`挂起当前Goroutine；
    2. 若Channel已经关闭且缓冲区没有任何数据，`runtime.chanrev`函数会直接返回；
    3. 若Channel的`sendq`队列中存在挂起的Goroutine，就会将`revx`索引所在的数据拷贝到接收变量所在的内存空间上并将`sendq`队列中Goroutine的数据拷贝到缓冲区；
    4. 若Channel的缓冲区中包含数据就会直接读取`recvx`索引对应的数据；
    5. 在默认情况下会挂起当前的Goroutine，将`runtime.sudog`结构加入`recvq`队列中并陷入休眠等待调度器的唤醒；

  会触发Goroutine调度的两个时机：

    1. 当Channel为空时；
    2. 当缓冲区不存在数据且不存在数据的发送者；

![image-20201206214849241](http://img.zhengyua.cn/img/20201206214849.png)

### 内存管理

在内存从分配到回收的生命周期中，内存不再被使用的时候，标准库会自动执行 Go 的内存管理。**内存管理被设计为可以在并发环境快速执行，同时与垃圾收集器集成在了一起**。

#### 堆和栈

- 在Go中**栈的内存由编译器自动进行分配和释放**，**存储函数参数、局部变量和调用函数帧**，随函数创建而分配，函数退出而销毁。

  **一个Goroutine对应一个栈**，栈是调用栈的简称，一个栈包含描述函数之间调用关系的栈帧，每一帧对应尚未返回的函数调用。

- 应用程序在运行时**只会存在一个堆**，**程序在运行期间可以主动从堆上申请内存**，这些内存由Go的内存分配器分配，并由垃圾收集器回收。

- 栈为Goroutine独有的，则**栈上的内存操作不需要加锁，而堆上的内存有时需要加锁防止多线程冲突**（因为Go的内存分配策略基于TCMalloc的线程缓存思想，在较小内存空间会尝试在`mcache`获取本地缓存中获取内存，在该内存中也是无锁的）。

- **堆上的内存回收需要经过完整的GC过程**，而栈上的内存分配和释放都比较简单，且栈内存能更好地利用CPU的缓存策略，因为**栈内存是连续的**。

#### 逃逸分析

- 关于对象分配到栈还是堆的问题，**Go编译器会尽可能将变量分配到栈上**。Go确定该问题就是通过逃逸分析。
- 编译器通过**逃逸分析技术去选择堆或者栈**，其基本思想为**检查变量的生命周期是否是完全可知的**，如果通过检查则可以在栈上分配。否则，就是所谓的逃逸，必须在堆上分配内存，即**栈逃逸到堆上**。
- 逃逸分析规则：
    - 逃逸分析时**在编译器完成的**，这是不同于jvm的运行时逃逸分析；
    - 如果变量在函数外部**没有引用**，则优先放到栈中；
    - 如果变量在函数外部**存在引用**，则优先放在堆上。
- 常见的逃逸情况：
    - **变量类型不确定**；
    - **暴露给外部指针**；
    - **变量所占内存较大**；
    - **变量大小不确定**；

#### 内存分配器

> 内存分配基于**TcMalloc，并发环境优化的内存分配器**。
>
> ![image-20201207132435299](http://img.zhengyua.cn/img/20201207132435.png)

- 对于小于32kb的，较小的内存空间的分配策略，**会尝试从`mcache`的本地缓存中获取内存**。此缓存持有`mspan`的内存块（span，32kb大小的内存块）列表，**`mspan`包含着可用于分配的内存**。

  > **span链表**被划分为8字节大小到32字节大小的，约70个大小等级，每个等级可以存储不同大小的对象。
  >
  > 每个链表会存在两份：**一个链表用于不包含指针的对象，另一个用于包含指针的对象**。这种区别可使GC更加轻松，不必扫描不包含任何指针的span。
  >
  > ![image-20201207131435096](http://img.zhengyua.cn/img/20201207131435.png)

  在分配内存时，当前的Goroutine会使用当前P的本地缓存，在span链表中寻找**第一个可用的空闲对象**，**获取本地缓存操作不需要锁，效率更高**。

  ![image-20201207131114472](http://img.zhengyua.cn/img/20201207131114.png)

- Go维护着每个大小等级的sapn的中央链表`mcentral`，其中维护着包含空闲对象的span和没有空闲对象的span。

  `mcentral`维护着**span的双向链表（前后指向span的引用），非空链表中的span可能包含着一些正在使用的内存**，“非空”表示在链表中至少有一个空闲的插槽可供分配。当GC清理内存时，可能会清理部分span，将该部分标记为不再使用，并将其放回非空链表。

  ![image-20201207131736842](http://img.zhengyua.cn/img/20201207131737.png)

  ![image-20201207131952815](http://img.zhengyua.cn/img/20201207131953.png)

- 若`central`中央链表中的空链表中没有可用的span，**新的span会从堆上分配，并链接到中央链表中**。

  ![image-20201207132144550](http://img.zhengyua.cn/img/20201207132144.png)

  **堆会在需要的时候从系统获取内存**，若需要更多的内存，堆会分配一个叫做`arena`的大内存，在64位架构下为64Mb，在其他架构下大多为4Mb。`arena`同样适用span映射内存。

  ![image-20201207132302391](http://img.zhengyua.cn/img/20201207132302.png)

- 对于超过32kb的分配，会向上取整到页的大小，并直接从堆上分配。

  ![image-20201207132359050](http://img.zhengyua.cn/img/20201207132359.png)


#### 垃圾收集器

现代高级编程语言管理内存方式：

- 手动
- 自动


其中PHP、Java和Go等语言使用自动的内存管理系统，有内存分配器和垃圾收集器来代为分配和回收内存。

其中垃圾收集器即为GC。

##### GC回收

GC负责**回收堆内存，而不负责回收栈中的内存**，因为栈是专用内存且数据较为简单，可用简单的编译器指令自动清理。

##### GC算法的种类

主流的垃圾回收算法有两大类：

- **追踪式垃圾回收算法**
- **引用计数法**

Go中所使用的三色标记法即属于前者的一种。

追踪式算法的核心思想在于**若对象不可达则可以在垃圾回收的控制循环里被GC回收**。

- 判断对象是否可达，通过找出所有的全局变量和当前函数栈里的变量，标记为可达，然后从已经标记的数据开始进一步标记他们可以访问的变量，以此内推。

##### Go的垃圾回收算法

- v1.5前使用**标记清除**（Mark-And-Sweep）算法
- v1.5后实现了基于**三色标记清除法**的并发垃圾收集器
- v1.8使用**混合写屏障**将垃圾收集时间缩短至0.5ms以内

###### 标记清除算法的缺点

此算法严格按照追踪式算法思路实现。

![](http://img.zhengyua.cn/img/20201011193341.png)


此算法主要有两个步骤：

1. 暂停应用程序的执行, 从根对象出发标记出可达对象。
2. 清除未标记的对象，恢复应用程序的执行。

**此算法最大问题在于**非异步进行垃圾回收，即GC执行期间需要把整个程序完全暂停。

###### 三色标记清除法

**三色标记清除算法背后的首要原则就是它把堆中的对象根据它们的颜色分到不同集合里面。**

此算法将程序的对象分为白、黑、灰三类：

- 白色对象—**潜在的垃圾**，其内存可能会被垃圾收集器回收
- 黑色对象—**活跃的对象**，包括不存在任何外部指针引用的对象以及从根对象可达的对象，垃圾回收器不会扫描这些对象的子对象。
- 灰色对象—**活跃的对象**，因为存在指向白色对象的外部指针，垃圾回收器会扫描这些对象的子对象。

**过程**：

- 第一步：在进入GC的三色标记阶段的一开始，所有对象都是白色的。

![](http://img.zhengyua.cn/img/20201011193941.png)

- 第二步：遍历根节点集合里的所有根对象，把根对象引用的对象标记为灰色，从白色集合放入灰色集合。

![](http://img.zhengyua.cn/img/20201011194027.png)

- 第三步：遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，之后将此灰色对象放入黑色集合。

![](http://img.zhengyua.cn/img/20201011194055.png)

- 第四步：重复第三步, 直到灰色集合中无任何对象。

![](http://img.zhengyua.cn/img/20201011194129.png)

- 第五步：回收白色集合里的所有对象，本次垃圾回收结束。

![](http://img.zhengyua.cn/img/20201011194142.png)

> 这里所说的根节点集合里的根对象就是栈上的对象或者堆上的全局变量。

##### 写屏障

> Go 在GC阶段执行三色标记前，还需要先做一个准备工作——打开写屏障(Write Barrier)。

三色标记法为**并发执行的算法**，但是在执行的时候函数栈可能会有新分配的对象，若想将这些新对象通知到GC或者将这些新对象着色，**就需要写屏障来执行，它会修改原先写逻辑，将新增的对象着色为灰色，保证不会影响当前GC**，而这些增加的灰色对象则会在后续的GC过程中回收，新的GC过程中已存的对象会重新标记为白色开始。

- 打开了写屏障可以保证了三色标记法在并发下安全正确地运行。

###### 三色不变性

并发或增量的标记算法中保证正确性，需要达成以下两种三色不变性中的任意一种：

- 强三色不变性 — 黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象；
- 弱三色不变性 — 黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径

###### 屏障技术

垃圾收集中的屏障技术就像是**钩子方法或者说中间件，会在读取、创建或者更新时执行的一段代码**。

可以分成读屏障和写屏障，因为读屏障性能影响大，所以往往采用写屏障保证三色不变性。

**Go的混合写屏障**：

Go在v1.7前使用**迪卡斯特插入写屏障保证强三色不变性**，但并没有在所有的垃圾收集根对象上开启插入写屏障。

- Go选择在标记阶段完成时暂停程序、将所有栈对象标记为灰色并重新扫描。

Go在v1.8组合迪卡斯特插入写屏障和Yuasa删除写屏障构成了混合写屏障，其目的就是为了**移除重扫描过程，因为重扫描对性能影响较大**。

除了引入混合写屏障之外，在垃圾收集的标记阶段，我们还需要将创建的所有**新对象都标记成黑色**，防止新分配的栈内存和堆内存中的对象被错误地回收，因为栈内存在标记阶段最终都会变为黑色，所以**不再需要重新扫描栈空间**。

- 该写屏障会将被覆盖的对象标记成灰色并在当前栈没有扫描时将新对象也标记成灰色

> 三色标记清除算法和混合写屏障后大大减少了暂停程序（STW）的时间，主要是在开启写屏障前和移除写屏障前暂停应用程序。

###### 完整的GC过程

Go的垃圾收集的整个过程可以分成:

- 标记准备
- 标记
- 标记终止
- 清除

每个阶段完成的工作如下：

**标记准备阶段**

- 暂停程序，所有的处理器在这时会进入安全点（Safe point）；

**标记阶段**

- 将状态切换至_GCmark、开启写屏障、用户程序协助（Mutator Assiste）并将根对象入队；
- 恢复执行程序，标记进程和用于协助的用户程序会开始并发标记（三色标记清除法）内存中的对象，**写屏障会将被覆盖的指针和新指针都标记成灰色，而所有新创建的对象都会被直接标记成黑色**；
- 开始扫描根对象，**包括所有 goroutine 的栈、全局对象以及不在堆中的运行时数据结构，扫描 goroutine 栈期间会暂停当前处理器**；
- 依次处理灰色队列中的对象，将对象标记成黑色并将它们指向的对象标记成灰色；
- 使用**分布式的终止算法检查剩余的工作**，发现标记阶段完成后进入标记终止阶段；

> 在标记开始的时候，收集器会默认抢占 25% 的 CPU 性能，剩下的75%会分配给程序执行。但是一旦收集器认为来不及进行标记任务了，就会改变这个 性能分配。
> 这个时候收集器会抢占程序额外的 CPU，**这部分被抢占 goroutine 有个名字叫 Mark Assist**。而且因为抢占 CPU的目的主要是 GC 来不及标记新增的内存。
> 除此以外 GC 还有一个额外的优化，一旦某次 GC 中用到了 Mark Assist，**下次 GC 就会提前开始**，目的是尽量减少 Mark Assist 的使用，从而避免影响正常的程序执行。

**标记终止阶段**

- 暂停程序、将状态切换至_GCmarktermination 并关闭辅助标记的用户程序；
- 清理**处理器上的线程缓存**；

**清理阶段**

- 将状态切换至_GCoff 开始清理阶段，初始化清理状态并关闭写屏障；
- 恢复用户程序，**所有新创建的对象会标记成白色**；
- 后台**并发清理所有的内存管理单元，当 goroutine 申请新的内存管理单元时就会触发清理**；

> 清扫的开销会增加到**分配堆内存的过程中，所以这个时间也是无感知的，不会与垃圾回收的延迟相关联**。

##### 总结


Go的GC最早期使用的回收算法是标记-清除算法，该算法需要在执行期间需要暂停应用程序(STW)，无法满足并发程序的实时性。后面Go的GC转为使用三色标记清除算法，并通过混合写屏障技术保证了Go并发执行GC时内存中对象的三色一致性（这里的并发指的是GC和应用程序的goroutine能同时执行）。一次完整的垃圾回收会分为四个阶段，分别是标记准备、标记、结束标记以及清理。在标记准备和标记结束阶段会需要 STW，标记阶段会减少程序的性能，而清理阶段是不会对程序有影响的。



#### 栈内存管理



## OS

### 自旋锁|互斥锁|读写锁

- 自旋锁：自旋就是忙等待的概念，基于互斥锁的自旋锁不会引起线程休眠，当共享资源不满足的时候自旋锁也不会不停地循环检测状态。

  **不会休眠就不会引起上下文切换**，会浪费CPU，即是优点也是缺点。

- 互斥锁：线程共享互斥量，为睡眠等待类型的锁，当线程抢互斥锁失败的时候，线程会陷入休眠。

  优点在于**节省CPU资源**，缺点在于**休眠唤醒需要时间**。

- 读写锁：对于临界区区分读和写锁，也为共享-独占锁，即读共享，写独占的锁。

  适用于**多读少写的场景**。

不管是什么锁，都是为了实现**保护共享资源**而提出的一种锁机制，都是为了对某项资源的互斥使用。

> 上述锁就是属于悲观锁，即在读取共享资源时先上锁。而乐观锁的思想就在于先读取共享资源后上锁，即后面再判断共享资源是否有更新。

### 网络I/O模型

**同步IO模型**：

1. 阻塞IO模型：若用户空间的应用程序执行一个系统调用，会导致应用程序阻塞，直到数据准备好，且从数据从内核复制进用户应用程序，最后进程处理数据。

   ![image-20201202143948421](http://img.zhengyua.cn/img/20201202143948.png)

2. 非阻塞IO模型：当执行系统调用时内核会立即返回，无论数据是否准备好，不断轮询数据是否准备好，期间可以获得足够的CPU时间继续做其他的事情。

   ![image-20201202144222032](http://img.zhengyua.cn/img/20201202144222.png)

3. 多路复用IO模型：多个I/O阻塞到同一个select线程的阻塞上，系统可在单线程的情况下同时处理多个客户端请求，应用程序主动等待且调用select函数获取数据状态信息，且进程状态为阻塞。

   ![image-20201202144656820](http://img.zhengyua.cn/img/20201202144657.png)

4. 信号驱动IO模型：内核通过应用进程发送的信号来决定信号对应的处理函数是否后续处理，期间为阻塞状态。

   ![image-20201202144804146](http://img.zhengyua.cn/img/20201202144804.png)

**异步IO模型**：

1. 异步IO模型：信号驱动的同时安装信号处理函数，进程继续运行并不阻塞。

   ![](http://img.zhengyua.cn/img/20201202145039.png)

#### I/O多路复用机制

- select

  每次调用初始化fd_set 结构体，利用**fd_set结构体在内核同时监控多个文件句柄**，通过FD_ISSET来查看具体某个文件句柄是否发生变化(ready/unready)。**其消息传递需要从内核拷贝传递到用户空间**。

  思路：有连接请求进行无差别轮询检查。

  问题：句柄上限+重复初始化+逐个排查所有文件句柄效率低。

- poll

  poll本质上和select没有区别，**结构体通过数组消除文件句柄上限**，同时使用不同字段分别标注事件，**来避免重复初始化**。

  思路：设计新的数据结构提供使用效率。

  问题：逐个排查所有文件句柄效率低。

- epoll

  **事件驱动**（每个事件关联上fd），调用返回的时候只给**发生了状态变化的应用提供（很可能是数据 ready）的文件句柄**，即利用**callback方式进行异步回调**。且利用mmap()**文件映射内存加速与内核空间的消息传递**；即epoll使用mmap减少复制开销。其消息传递通过**内核和用户空间共享同一块内存**。

  思路：只返回状态变化的文件句柄。

  问题：依赖特定平台（Linux）+ 存在上限（但是相对于前面两种很大）。

> epoll支持水平触发和边缘触发。且对文件描述符的操作有两种模式：
>
> - LT模式：缺省的工作方式，并且同时支持**block和no-block socket**；当epoll_wait检测到描述符事件发生并将此事件通知应用程序，**应用程序可以不立即处理该事件**。下次调用epoll_wait时，会再次响应应用程序并通知此事件。
> - ET模式：高速工作方式，只支持**no-block socket**。当epoll_wait检测到描述符事件发生并将此事件通知应用程序，**应用程序必须立即处理该事件**。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。

#### AIO|BIO|NIO

![image-20201202150551204](http://img.zhengyua.cn/img/20201202150551.png)

## Redis

Redis是一个**开源的、基于内存、单线程的**，也可以进行**持久化的**，基于**C语言编写的键值对数据库**。

### Redis为什么这么快

单机的redis可以支撑每秒10几万的高并发，性能是mysql的几十倍。主要有以下原因：

- 完全基于**内存操作**；
- C语言实现，**优化过的数据结构**，基于几种基础的数据结构，redis做了大量的优化，性能极高；
- 使用**单线程**，无上下文的切换成本；
- 基于**非阻塞的IO多路复用机制**；

### Redis多线程

redis使用多线程是**用于处理数据的读写和协议解析**，使用单线程模型来处理客户端的请求，执行命令还是使用单线程。

目的在于redis的性能瓶颈**在于网络IO而非CPU**，使用多线程能够提升IO读写的效率，从而整体提高redis的性能。

### Redis事务机制

redis通过`MULTI`、`EXEC`、`WATCH`等命令来实现事务机制，事务执行过程**将一系列多个命令按照顺序一次性执行**，并且在执行期间，事务不会被中断，也不会去执行客户端的其他请求，直到所有命令执行完毕。事务的执行过程如下：

1. 服务端收到客户端请求，事务以MULTI开始；
2. 如果客户端正处于事务状态，则会把事务放入队列同时返回给客户端QUEUED，反之则直接执行这个命令；
3. 当收到客户端EXEC命令时，WATCH命令监视整个事务中的key是否有被修改，如果有则返回空回复到客户端表示失败，否则redis会遍历整个事务队列，执行队列中保存的所有命令，最后返回结果给客户端；

**WATCH的机制本身是一个CAS的机制**，被监视的key会被保存到一个链表中，如果某个key被修改，那么`REDIS_DIRTY_CAS`标志将会被打开，这时服务器会**拒绝执行事务**。

### Redis实现高可用

#### 主从架构

主从模式是最简单的实现高可用的方案，核心就是主从同步。主从同步的原理如下：

1. **slave发送sync命令到master**；
2. **master收到sync之后，执行bgsave，生成RDB全量文件**；
3. **master把slave的写命令记录到缓存**；
4. **bgsave执行完毕之后，发送RDB文件到slave，slave执行**；
5. **master发送缓存中的写命令到slave，slave执行**。

> 在redis2.8版本之后已经使用psync来替代sync了，原因是sync命令非常消耗系统资源，而psync的效率更高。

![image-20201209113517064](C:%5CUsers%5Ctudou%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201209113517064.png)

#### 哨兵

基于主从方案的缺点还是很明显的，假设master宕机，那么就不能写入数据，那么slave也就失去了作用，整个架构就不可用了，除非你手动切换，主要原因就是因为**没有自动故障转移机制**。而哨兵(sentinel)的功能比单纯的主从架构全面的多了，它具备**自动故障转移、集群监控、消息通知等功能**。

![image-20201209113555245](http://img.zhengyua.cn/img/20201209113734.png)

哨兵可以同时监视多个主从服务器，并且在被监视的master下线时，自动将某个slave提升为master，然后由新的master继续接收命令。整个过程如下：

1. **初始化sentinel，将普通的redis代码替换成sentinel专用代码**；
2. **初始化masters字典和服务器信息，服务器信息主要保存ip:port，并记录实例的地址和ID**；
3. **创建和master的两个连接，命令连接和订阅连接，并且订阅sentinel:hello频道**；
4. **每隔10秒向master发送info命令，获取master和它下面所有slave的当前信息**；
5. **当发现master有新的slave之后，sentinel和新的slave同样建立两个连接，同时每个10秒发送info命令，更新master信息**；
6. **sentinel每隔1秒向所有服务器发送ping命令，如果某台服务器在配置的响应时间内连续返回无效回复，将会被标记为下线状态**；
7. **选举出领头sentinel，领头sentinel需要半数以上的sentinel同意**；
8. **领头sentinel从已下线的的master所有slave中挑选一个，将其转换为master**；
9. **让所有的slave改为从新的master复制数据**；
10. **将原来的master设置为新的master的从服务器，当原来master重新回复连接时，就变成了新master的从服务器**；

sentinel会每隔1秒向所有实例（包括主从服务器和其他sentinel）发送ping命令，并且根据回复判断是否已经下线，这种方式叫做**主观下线**。当判断为主观下线时，就会向其他监视的sentinel询问，如果超过半数的投票认为已经是下线状态，则会标记为**客观下线状态**，同时**触发故障转移**。

### redis集群

如果说依靠哨兵可以实现redis的高可用，如果还想在支持高并发同时容纳海量的数据，那就需要redis集群。redis集群是redis提供的分布式数据存储方案，集群通过数据分片sharding来进行数据的共享，同时提供**复制和故障转移的功能**。

#### 节点

一个redis集群由多个节点node组成，而多个node之间通过cluster meet命令来进行连接，节点的握手过程：

1. **节点A收到客户端的cluster meet命令**
2. **A根据收到的IP地址和端口号，向B发送一条meet消息**
3. **节点B收到meet消息返回pong**
4. **A知道B收到了meet消息，返回一条ping消息，握手成功**
5. **最后，节点A将会通过gossip协议把节点B的信息传播给集群中的其他节点，其他节点也将和B进行握手**

![image-20201209113726224](http://img.zhengyua.cn/img/20201209113726.png)

#### 槽slot

redis通过集群分片的形式来保存数据，整个集群数据库被分为16384个slot，集群中的每个节点可以处理0-16384个slot，当数据库16384个slot都有节点在处理时，集群处于上线状态，反之只要有一个slot没有得到处理都会处理下线状态。通过cluster addslots命令可以将slot指派给对应节点处理。

slot是一个位数组，数组的长度是16384/8=2048，而数组的每一位用1表示被节点处理，0表示不处理，如图所示的话表示A节点处理0-7的slot。

当客户端向节点发送命令，如果刚好找到slot属于当前节点，那么节点就执行命令，反之，则会返回一个MOVED命令到客户端指引客户端转向正确的节点。（MOVED过程是自动的）

如果增加或者移出节点，对于slot的重新分配也是非常方便的，redis提供了工具帮助实现slot的迁移，整个过程是完全在线的，不需要停止服务。

#### 故障转移

如果节点A向节点B发送ping消息，节点B没有在规定的时间内响应pong，那么节点A会标记节点B为pfail疑似下线状态，同时把B的状态通过消息的形式发送给其他节点，如果超过半数以上的节点都标记B为pfail状态，B就会被标记为fail下线状态，此时将会发生故障转移，优先从复制数据较多的从节点选择一个成为主节点，并且接管下线节点的slot，整个过程和哨兵非常类似，都是基于Raft协议做选举。

### 缓存穿透|缓存雪崩|缓存击穿

- 缓存穿透：绕过缓存故意查询不存在的key，查询结果为空无法缓存。
    - 解决办法：
        - 增加参数校验，不合法的参数直接返回；
        - 将该不合法的值也加入缓存，并设置合理的过期时间；
        - 使用布隆过滤器（Bloom Filter）；
- 缓存击穿：接收着高并发的热点key突然失效
    - 解决方法：
        - 互斥锁（Redis/Zookper）；
        - 提前使用互斥锁，将过期时间延长或重新设置；
        - 设置热点数据永不过期；
        - 利用hystrix做资源的隔离保护主线程池，进行资源保护。
- 缓存雪崩：在同一时间缓存大面积失效。
    - 解决方法：
        - Key的失效时间增加随机值而不是同一时间；
        - 做二级缓存，一级缓存失效后使用二级缓存；
        - 缓存失效后通过加锁或者队列来控制读数据库写缓存的线程数量；

### 淘汰删除策略

**内存淘汰策略**：均在内存不足以容纳新写入数据条件下

- 第一类：不处理，等报错（默认配置）
    - noeviction：当内存使用达到阈值时，所有引起申请内存的命令报错；
- 第二类：从所有结果集中的key中挑选进行淘汰
    - allkeys-random：随机淘汰；
    - allkeys-lru：最近最少使用的keys淘汰；
    - allkeys-lfu：使用频率最低的key淘汰；（4.0版本更新）
- 第三类：在设置过期时间的键空间中挑选淘汰
    - volatile-random：随机淘汰；
    - volatile-lru：最近最少使用的keys淘汰；
    - volatile-ttl：可存活时间最短的key淘汰；
    - volatile-lfu：使用频率最低的key淘汰；

**删除策略**：

- 定时删除：针对创建时设置了过期时间的key。

  会内存友好但会占用大量CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。

- 惰性删除：在访问key时判断该key是否过期，过期则删除。

  最大化地节省CPU资源，对内存不友好，极端情况下会出现过期key占用过多内存。

- 定期删除：设置时间间隔下检查数据库中失效的key，并删除过期key。

  对CPU和内存资源达到最优的平衡效果。

### Redis数据结构

#### 基本数据类型

1. **字符串**：redis没有直接使用C语言传统的字符串表示，而是自己实现的叫做简单动态字符串SDS的抽象类型。C语言的字符串不记录自身的长度信息，而SDS则保存了长度信息，这样将获取字符串长度的时间由O(N)降低到了O(1)，同时可以避免缓冲区溢出和减少修改字符串长度时所需的内存重分配次数。
2. **链表linkedlist**：redis链表是一个双向无环链表结构，很多发布订阅、慢查询、监视器功能都是使用到了链表来实现，每个链表的节点由一个listNode结构来表示，每个节点都有指向前置节点和后置节点的指针，同时表头节点的前置和后置节点都指向NULL。
3. **字典hashtable**：用于保存键值对的抽象数据结构。redis使用hash表作为底层实现，每个字典带有两个hash表，供平时使用和rehash时使用，hash表使用链地址法来解决键冲突，被分配到同一个索引位置的多个键值对会形成一个单向链表，在对hash表进行扩容或者缩容的时候，为了服务的可用性，rehash的过程不是一次性完成的，而是渐进式的。
4. **跳跃表skiplist**：跳跃表是有序集合的底层实现之一，redis中在实现有序集合键和集群节点的内部结构中都是用到了跳跃表。redis跳跃表由zskiplist和zskiplistNode组成，zskiplist用于保存跳跃表信息（表头、表尾节点、长度等），zskiplistNode用于表示表跳跃节点，每个跳跃表的层高都是1-32的随机数，在同一个跳跃表中，多个节点可以包含相同的分值，但是每个节点的成员对象必须是唯一的，节点按照分值大小排序，如果分值相同，则按照成员对象的大小排序。
5. **整数集合intset**：用于保存整数值的集合抽象数据结构，不会出现重复元素，底层实现为数组。
6. **压缩列表ziplist**：压缩列表是为节约内存而开发的顺序性数据结构，他可以包含多个节点，每个节点可以保存一个字节数组或者整数值。

Redis的主要数据结构有字符串、Hash哈希表、List列表、Set集合、ZSet有序集合等；

#### 简单动态字符串的理解

对C语言中的字符串进行封装和优化，解决了以下问题：

- 字符串**二进制不安全**，以空字符来作为结束位；
- 频繁修改字符串时会涉及到**内存的重新分配**，比较消耗性能。

Redis中的简单动态字符串结构，除了包含一个字符数组的属性，还包含数组的长度和数组的实际使用长度等属性，以**确定长度边界保证字符串是二进制安全的**，从而可以保存任意类型的数据，且通过**内存预分配和惰性空间**释放解决内存性能的问题。

使用场景：

- 字符除了可以存储字符类型的数据，也可以存储**数字类型的数据**，通过INCR、DECR等命令数字进行加减，所以可以用作**计数器**；
- C语言中每个字符占一个字节，有8个二进制位，所以可以当作**位数组来使用**，通过setbit、getbit等命令来对位数组进行赋值取值，可以以**很小的空间来保存类似签到数据的大量数据**，以及Redis中的**布隆过滤器也是通过位数组来实现的**。

字符串底层存储对应的RedisObject：

```c
struct RedisObject {
    int4 type; 
    int4 encoding; 
    int24 lru; 
    int32 refcount; 
    void *ptr; 
} robj;
```

字符串有两种存储方式，int编码，embstr编码和raw编码。

- int编码

  当value是一个整数且可以使用long类型（8字节）来表示时为int编码，**ptr直接存储数值**。（Redis进行优化，创建0-9999的字符串对象作为共享变量）。

- embstr编码和raw编码

  两种编码都是RedisObject和SDS结构来存储字符串，区别在于，embstr编码**适合存储长度较小的字符串**，其RedisObject结构与ptr指向的SDS结构在内存中是连续的，**内存分配次数和内存释放次数均是一次**。而raw编码分别**调用两次内存分配**来创建RedisObject结构和SDS结构。

#### Hash对象的理解

value可为hash表，底层编码可以是**ziplist（压缩链表）**，也可以是**hashtable哈希表**。

默认情况下，**当元素小于512个（64个字节）时底层使用ziplist存储数据**。

- ziplist

  元素保存的**字符串长度较短且元素个数较小**时会使用ziplist，ziplist是一块**连续的内存**，里面每一个节点保存了对应的kye和value，然后节点都紧凑地存储在一起，**优点在于充分利用内存空间，缺点在于插入新元素时需要调用realloc扩展内存**。（可能会进行内存重分配，将内容拷进去，也有可能在原有地址上进行扩展）。

- hashtable

  元素较多时会使用hashtable编码，RedisObject的ptr会指向一个**dict结构**，该结构中的ht数组下标0和1分别通常使用**保存键值对、在渐进式rehash**使用。hashtable通过**链地址法**来解决冲突，table数组存储的是**链表的头结点**。

- 渐进式rehash

  当负载因子>=1时，进行哈希表扩展操作；

  当负载因子<0.1时，进行哈希表收缩操作；

  渐进式的意义在于**不是一次性完成rehash**，因为会对性能产生影响，具体执行步骤是：

    1. 初始化

       首先将对dict结构中**ht[1]哈希表分配空间**（大小取决于最接近实际适用空间的2的n次方幂），然后将rehashindex属性设置为0。

    2. 转移

       然后每次对ht[0]中的元素进行增删改查时，除了执行指定操作外，还会**对应下标的所有键值对rehash到ht[1]，并且会将rehashindex+1**。

    3. 更改指针指向

       当ht[0]所有键值对都rehash到ht[1]后，对**两者指针进行互换**，同时将rehashindex设置为-1，代表rehash完成。

#### List对象的理解

列表list的底层数据结构为**链表**，**插入删除操作很快，但随机访问较慢，时间复杂度为O(n)**。

Redis中的list可以作为一个**队列来使用**，也可以作为一个**栈来使用**，在实际应用中常用来做**异步队列**，将延时处理的任务序列化后插入队列，等待其他线程从列表中取出消费。

- quicklist

  老版本中的Redis**元素较小时使用ziplist作为底层编码，元素较多时使用双向链表linkedlist作为底层编码**。

  但由于双向链表需要存储pre、next指针需要占用16字节，且每个节点内存都是单独分配，加剧了内存碎片化。

  新版本使用quicklist作为底层编码，它**为双向链表但每一个节点是一个ziplist**。

#### Set对象的理解

Set是一个无序的、无重复的字符串集合，底层编码有**inset和hashtable两种**。

- inset编码

  当**元素都为整数，且元素个数较少时**使用inset作为底层编码，inset结构中有一个contents属性，content是一个整数数组，**从小到大保存**了所有元素。

- hashtable编码

  当**元素个数较多时**，Set使用hashtablle来保存元素，元素的值作为key，value都为NULL。

#### 有序集合ZSet对象的理解

ZSet与Set的区别在于ZSet的元素都有一个Score属性，可以理解为权重，存储时会根据该Score有序排列。其**底层数据结构为跳跃表**。

- ziplist编码

  当**元素较少时使用ziplist作为底层编码**，所有元素按照Score从低到高排序。

- skiplist+dict

  当**元素较多时使用skiplist+dict来实现**，skiplist存储元素的值和score，并将所有元素有序排列，实现时间复杂度为O(logn)进行增删改查，且能够根据Score来进行范围查找。

  **dict存储元素的值和Score的映射关系**，便于以O(1)的时间复杂度查找元素对应的Score值。

#### 布隆过滤器

从功能上来说就是一个**有误差的Set对象**，特点在于使用布隆过滤器判断元素是否存在时，若返回结果为存在，则实际上有可能是不存在的，若**返回结构为不存在，则实际上肯定不存在**。

布隆过滤器的数据结构就是**大型的位数组，通过多个hash函数处理key**，将key得到的几个hash值与布隆过滤器的位数组的size取模得到下标，然后在数组中这些下标位置都置为1。

#### Redis对跳跃表的优化

跳跃表就是链表的基础上增加了多层索引节点，每层索引节点都有范围规律，且底层链表才保存节点数据，将**链表查找的时间复杂度变为O(logn)**，类似于B+树。但是全索引结构的缺点就在于**插入新节点之后就无法添加新的索引节点**，可能就导致某一个索引范围内的节点数过多，将查找的时间复杂度退化为O(n)。

Redis对于此缺点进行优化，在**分配索引节点时计算出一个随机数表示添加的索引层数**，以此来计算索引节点需要分配的索引层数。通过此优化，使**索引节点分布不均匀，也相应优化空间复杂度**。



## MySQL





## Computer Network

### DNS

#### DNS解析过程

![preview](http://img.zhengyua.cn/img/20201206114748.jpeg)

- 主要过程为Web浏览器进程调操作系统中的`gethostbyname`函数，此函数会通过网卡给DNS服务器发送UDP请求，接收结果后返回给浏览器。

实际情况中会先查询浏览器的dns缓存再调用`gethostbyname`函数，在调用`gethostbyname`函数试图DNS解析之前会检查域名是否在本地Hosts中。

#### DNS中的TCP/UDP应用

- 使用到TCP协议的地方：区域传送；

  区域传送就是在DNS主服务器和DNS辅助服务器之间建立通信并加载数据信息。

  其中主服务器和辅助服务器中的同步数据可能会超过512字节，且同步的内容要保证可靠性，利用TCP协议实现可靠性。

- 使用到UDP协议的地方：域名解析；

  `gethostbyname`函数通过网卡向DNS服务器发送请求。

  因为在查询域名的IP信息时一般返回的内容不超过512字节（UDP协议传输内容不能超过512字节），利用UDP可以快速得到返回。

#### 域名解析原理及过程

- linux中的`dig`命令显示域名解析的过程。

DNS的查询参数一般有三个：

1. 域名；
2. Class：互联网下值为`IN`，互联网之外为其他值；
3. 记录类型：标识域名对应何种类型的记。类型A为域名对应的IP地址，类型MX为域名对应的邮件服务器，类型PTR为根据IP地址反查域名，类型CNAME为查询域名相关别名。

根域名（末尾为`.`）-》顶级域名（TLD，如`.team）-》次级域名（SLD，如`.redrock`）-》主机名（host，如`www`）

- 解析流程就是**分级查询**。

#### 使用CNAME优势

根据用户所在位置选择并返回最优节点IP，实现CDN加速域名的效果。





### 浏览器中输入URL到返回页面的过程

1. 根据域名进行DNS域名解析；
2. 拿到解析的IP地址建立TCP连接；
3. 向IP地址发送HTTP请求；
4. 服务器处理请求；
5. 返回相应结果；
6. 关闭TCP连接；
7. 浏览器解析HTML；
8. 浏览器布局渲染；

#### 建立TCP连接是否会在HTTP请求完成后的关闭问题

- 在HTTP/1.0中，一个服务器在响应HTTP请求后会断开TCP连接，即连接无法复用；
- 在HTTP/1.1中，将长连接即`Connection`字段加入后默认开启长连接，将连接进行复用；

#### 一个TCP连接对应几个HTTP请求

- 如果维持长连接，一个TCP连接可以对应多个HTTP请求。

#### 一个TCP连接中同时发送HTTP请求

- HTTP/1.1存在的问题是单个TCP连接在同一时刻只能处理一个请求即从HTTP请求开始到结束在同一个TCP连接中两个请求的生命周期不能重叠，虽然HTTP/1.1引进了Pipelining技术试图解决该问题，但此功能在浏览器中默认是关闭的，因为有以下原因：
    - 一些代理服务器并不能正确处理HTTP Pipelining；
    - 正确的流水线实现是复杂的；
    - Head-of-line Blocking连接头阻塞会造成首个请求阻塞其他等待的请求。
- HTTP/2.0提供了Multiplexing多路传输特性，在一个TCP连接中同时完成多个HTTP请求。

- 在HTTP/1.1时代浏览器通过以下手段提高页面的加载效率：
    - 维持和服务器已经建立的TCP链接，在同一连接上顺序处理多个请求；
    - 和服务器建立多个TCP连接。

> Pipelining：一个支持持久连接的客户端可以在一个连接中发送多个请求（不需要等待任意请求的响应）。收到请求的服务器必须按照请求收到的顺序发送响应。

#### 刷新页面不需要重新建立SSL连接

- TCP长连接时就不用再次SSL握手。

#### 浏览器对同一Host建立TCP连接到数量限制

- 有限制。Chrome最多允许对同一个Host建立六个TCP连接。

> 若几十张图片的加载，在HTTPS连接且在同一个域名下浏览器会在SSL握手后可能使用HTTP/2.0，通过Multiplexing多路传输

### HTTP

#### 概括HTTP

- HTTP是一个在计算机世界里面专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范。

> HTTP通常跑在TCP/IP协议栈上，依靠IP协议实现寻址和路由、TCP协议实现可靠数据传输、DNS协议实现域名查找、SSL/TLS协议实现安全通信。WebSocket、HTTPDNS依赖于HTTP。

#### HTTP各版本比较

- HTTP/1.0

    - 无状态/无连接；
    - 连接无法复用；
    - 队头阻塞：导致带宽无法被充分利用，以及后续影响健康请求被阻塞；

- HTTP/1.1

    - 缓存处理：新增字段`cache-control`；
    - 长连接：新增Connection字段，默认设置keep-alive保持连接不断开；
    - 管道化：基于上面长连接的基础，管道化可以不等第一个请求响应继续发送后面的请求，但响应顺序以请求顺序返回；
    - 断点传输；

  > HTTP/1.1不能实现多路复用的原因：
  >
  > - 不是二进制传输，也没有帧和流的概念，无法将多个响应结果进行拼接；
  > - HTTP/1.x是序列和阻塞机制，而HTTP/2.0是多工复用TCP连接，避免了队头阻塞；

- HTTP/2.0
    - 二进制分帧和流传输；
    - 多路复用：在共享TCP连接的基础上同时发送请求和响应；
    - 头部压缩：HPACK算法；
    - 服务器推送：服务器可以额外的向客户端推送资源，而无需客户端明确的请求；



#### HTTP特点及缺点

- 特点：
    - HTTP协议支持客户端/服务端模式，也是一种请求/响应模式的协议；
    - 灵活可扩展：一个是语义上的自由，只规定了基本格式，其他的各部分没有严格的限制；二个是它允许传输任意类型的数据类型，传输类型以`Content-Type`加以标记；
    - 可靠传输，HTTP基于TCP/IP；
    - 无状态，每一次请求都是独立无关的；

> 持久连接：减少了TCP连接和断开的额外开销，减少了服务端的负载，Web页面加载变快。

- 缺点：
    - 明文传输（不加密），其内容可能被窃听；
    - 无法验证报文的完整性，内容可能被篡改；
    - 不验证通信的身份，有可能遭遇伪装；
    - 无状态；
    - 队头阻塞，HTTP/2多路复用在HTTP层面解决此问题，与TCP队头阻塞不同；

#### HTTP请求方法

##### HTTP中的幂等

- 一个方法幂等是根据一个方法执行次数与产生的结果是否有副作用或者一样，如果是幂等则意味着成功执行请求的结果和它的执行次数无关。请求方式中只有POST和PATCH是非幂等的。

##### GET和POST的区别

- 从缓存的角度上说，GET会被浏览器主动缓存下来，留下历史记录，而POST不会；
- 从编码的角度上说，GET只能进行URL编码，它只能接收ASCII字符，但POST不受限制；
- 从参数的角度上说，GET一般放在URL上传递参数，POST放在请求体里，更适合传递敏感信息；
- 从幂等的角度上说，GET是幂等的，POST不是；
- 在TCP连接上，GET和POST并无区别，但是由于HTTP的规定和浏览器/服务器的限制，导致它们在应用过程中产生了一些不同；
- 从TCP的角度上说，GET请求会一次性将请求报文发送出去，而POST请求除在特殊浏览器（火狐）外会分为两个TCP数据报，首先发送的是Header部分，若服务器响应100（Continue），则会发送body部分。

##### 支持度

- OPTIONS、CONNET、TRACE只在HTTP/1.1上支持；
- LINK、UNLINK在HTTP/1.1中被废弃。

##### 服务端收到不支持的请求方法会如何处理

- 当服务端接收到不支持的请求方法时会返回`405(Method Not Allowed)`，并且会把所有支持的方法写入响应报文首部字段`Allow`中返回。

#### HTTP状态码

- 1xx 信息性

  请求已经接收到需要进一步处理才能完成（HTTP/1.0不支持）。

  `101 Seitching Protocols	`：升级Websocket变更成功返回；

- 2xx 成功状态

  成功处理请求。

  `200 OK`：请求成功，通常返回的数据中带有响应体；

  `204 No Content`：意思和`200`一致，但表示返回的数据中没有带响应体；

  `206 Partial Content`：客户端进行了范围请求且服务端正常处理，响应报文的首部应该还有`Content-Range`字段指定实体的范围。

- 3xx 重定向

  重定向状态，资源位置发生变动，需要重新请求。

  `301 Moved Permanently`：永久重定向，最新的URL为响应报文首部的`Location`字段。浏览器会默认做缓存优化，减少服务器压力，在第二次访问时自定重定向到那个网址；

  `302 Found`：临时重定向，表示请求资源暂时移动到别的URL上，不会被缓存；

  `303 See Other`：与`302`类似，但表示客户端应该使用GET方法获取资源；

  `304 Not Modefied`：客户端带条件请求时虽没满足条件但服务端也允许返回该资源，与重定向并没有关系；（eg：协商缓存成功返回`304`，表示请求的资源在服务器上并没发生改变，告诉请求者可以使用缓存。）

  `307 Temprary Redirect`：临时重定向，但比`302`更加明确，重定向的请求方法和实体都不允许变动。（场景例如，`HSTS协议`，强制客户端使用HTTPS连接。）

- 4xx 客户端错误

  客户端出现错误。

  `400 Bad Request`：请求报文中存在语法错误，但并没有指出具体是哪里；

  `401 Unauthorized`：需要有通过HTTP认证的认证信息或用户认证失败；

  `403 Forbidden`：请求资源被拒绝，如法律禁止、敏感信息等；

  `404 Not Found`：请求资源未找到，表示未在服务器上找到相应的资源。

- 5xx 服务端出现错误

  服务端出现错误。

  `500 Internal Server Error`：服务器内部错误，但并没有指出具体是哪里；

  `501 Not Implemented`：表示客户端请求的功能还不支持；

  `502 Bad Gateway`：服务器是正常的，但代理服务器无法获取到合法响应；

  `503 Service Unavaible`：服务器内部处于超负载状态或进行停机维护；

#### HTTP报文

##### 整体结构

- 整体结构：报文首部 + 空行 + 报文实体

![image-20201203150222506](http://img.zhengyua.cn/img/20201203150222.png)

请求报文：

![image-20201203145956365](http://img.zhengyua.cn/img/20201203145956.png)

响应报文：

![image-20201203150058868](http://img.zhengyua.cn/img/20201203150058.png)

##### HTTP首部字段

四种首部字段类型：

- 通用首部字段（General Header Fields）；
- 请求首部字段（Request Header Fields）；
- 响应首部字段（Response Header Fields）；
- 实体首部字段（Entity Header Fields）。

###### 通用首部字段

![image-20201203152813085](http://img.zhengyua.cn/img/20201203152813.png)

- `Connection`首部字段有一个值是`keep-alive`，表示开启持久连接。
- 还有一个首部字段也叫`Keep-Alive`，允许消息发送者暗示连接的状态，还可以用来设置超时时长和最大请求数。

###### 请求首部字段

![image-20201203153800945](http://img.zhengyua.cn/img/20201203153801.png)

###### 响应首部字段

![image-20201203154204416](http://img.zhengyua.cn/img/20201203154204.png)

###### 实体首部字段

![image-20201203155035536](http://img.zhengyua.cn/img/20201203155035.png)

###### 非标准的首部字段

因为HTTP首部字段是可以自行扩展的，所以在Web浏览器和浏览器的应用上出现了一些非标准的首部字段：

![image-20201203155607381](http://img.zhengyua.cn/img/20201203155607.png)

###### Accept相关字段

- 当有多个字段值的时候，可以指定字段q作为权重，范围为[0,1]；

- 五种类别：

  ![image-20201203155817301](http://img.zhengyua.cn/img/20201203155817.png)

#### 编码提升传输速率

- 内容编码

  通常对实体内容进行压缩编码，目的是优化传输。

  涉及的字段有`Content-Encoding`、`Content-Length`、`Content-Type`、`Accept-Encoding`；

  涉及到的内容编码方式：gzip、compress、defalte、identity、br；

  ![image-20201203190934751](http://img.zhengyua.cn/img/20201203190934.png)

- 传输编码

  用来改变报文格式，通常在头部加入`Tansfer-Encoding:chunked`，实现分块编码，解决了不依赖头部的长度消息也能知道实体的边界。

  ![image-20201203191047623](http://img.zhengyua.cn/img/20201203191047.png)

#### HTTP的缓存策略

主要分为强缓存和对比缓存，优先级：

- 强缓存（Cache-Control）> 强缓存（Expires）> 对比缓存（Etag/If-None-Match）> 对比缓存（Last-Modified/If-Modified-Since）

##### 强制缓存

- 浏览器缓存数据库里有缓存数据就不再向服务端发送请求了。

可造成强制缓存的字段有`Expires`和`Cache-Control`：

- `Expires`：表示缓存到期时间，是绝对时间（服务器时间+缓存有效时间）；

- `Cache-Contorl`：该字段表示缓存最大有效时间，是相对时间。

  > `Cache-Control`的字段：
  >
  > - max-age：即最大有效时间；
  > - no-cache：表示没有缓存；
  > - s-maxage：同max-age，但是仅用于共享缓存，如CDN缓存；
  > - public：多用户共享缓存，默认设置；
  > - private：禁止多用户共享，HTTP认证之后，字段会自动转换成private。

##### 对比缓存

- 先给服务器发请求并携带缓存资源文件的标识，服务器进行对比后，若资源文件没有修改则返回304，浏览器使用缓存的资源文件，反之则返回更新后的资源文件。

可实现对比缓存的机制有`Last-Modified/if-Modified-Since`和`Etag/if-None-Match`，前者为返回首部字段，后者为请求首部字段，服务器判断资源文件是否有更新，来决定返回最新的资源文件（200），还是浏览器缓存（304）：

- `Last-Modified/if-Modified-Since`

  时间作为标识。

  缺点：

    - 前者标注只能精确到秒级；
    - 若某些文件被定期生成，同时内容并没有变化，虽然前者变了但是缓存会重新生成；

- `Etag/if-None-Match`

  版本号作为标识。

### TCP/UDP

TCP 是一个可靠的（reliable）、面向连接的（connection-oriented）、基于字节流（byte-stream）、全双工的（full-duplex）协议。



#### TCP报文与UDP报文

- TCP报文：

  ![image-20201203201219248](http://img.zhengyua.cn/img/20201203201219.png)

- UDP报文：



#### TCP三次握手

![image-20201203200934643](http://img.zhengyua.cn/img/20201203200934.png)

![image-20201203201729111](C:%5CUsers%5Ctudou%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201203201729111.png)

重点在于交换彼此的 ISN（初始序列号）。

凡是消耗序列号的 TCP 报文段，一定需要对端确认。如果这个段没有收到确认，会一直重传直到达到指定的次数为止。

三次是最少的安全次数，两次不安全，四次浪费资源。

##### SYN字段不携带数据却要消耗一个序列号

**不占用序列号的段是不需要确认的**，因为没有内容。SYN端需要对方的确认所以需要占用一个序列号。

##### 除交换彼此的序列号外

除了交互彼此的序列号外，TCP握手另一个重要作用就是交换一些辅助信息，如最大段大小（MSS）、窗口大小（Win）、窗口缩放因子（WS）、是否支持选择确认（SACK_PERM）等。

##### 初始序列号ISN

ISN生成的算法是随时间变化，会递增的分配给后续的TCP连接的ISN。

出于以下两点的考虑，ISN不能设置为固定值：

- 出于安全性考虑，知道ISN后可伪造RST包；
- 因开启SO_REUSEADDR以后允许端口重用，动态递增的ISN可保证两个连接的ISN不会相同，不会串包。

##### 全连接队列和半连接队列

- 半连接队列：服务端收到客户端的 SYN 包，回复 SYN+ACK 但是还没有收到客户端 ACK 情况下，会将连接信息放入半连接队列。半连接队列又被称为 SYN 队列。
- 全连接队列：服务端完成了三次握手，但是还未被 accept 取走的连接队列。全连接队列又被称为 Accept 队列。
- 半连接队列的大小与用户 listen 传入的 backlog、net.core.somaxconn、net.core.somaxconn 都有关系；
- 全连接队列的大小是用户 listen 传入的 backlog 与 net.core.somaxconn 的较小值；

##### SYN FLOOD攻击

![image-20201204013445914](http://img.zhengyua.cn/img/20201204013446.png)

应对SYN FLOOD攻击：

- 增加SYN连接数：`tcp_max_syn_backlog`；
- 减少`SYN+ACK`重试次数：`tcp_synack_retries`；

- SYN Cookie机制：三次握手的最后阶段分配连接资源，缺点在于MSS值固定且较少和无状态机制即服务端不保存状态，不能使用其它所有TCP选项。

  ![image-20201204013629627](http://img.zhengyua.cn/img/20201204013629.png)

#### TCP四次挥手

![image-20201204011028202](http://img.zhengyua.cn/img/20201204011028.png)

##### 半关闭

客户端发送FIN包就不能再发送数据包给服务端了，但是还可以接收服务端发送的数据包，此状态即为半关闭状态。

##### FIN报文消耗一个序列号

若FIN报文不消耗序列号，则客户端不能确定该返回的ACK包是服务端发送过来的数据包还是FIN包。

##### 三次挥手

因为有延迟确认的存在且服务端确定在客户端关闭之前没有数据返回，则服务端的ACK+FIN可以同时发送，从而实现三次挥手；

##### TIME_WAIT状态

存在的原因：

- 数据报文可能在发送途中会延迟到最终会到达，这种情况就会造成相同源端口和目的端口创建新连接时可能受到旧数据包，造成数据错乱；
- 确保可靠TCP实现全双工终止连接，若出现服务端发送FIN包时丢失且此时客户端没有进入TIME_WAIT阶段直接CLOSED返回一个ACK包，若ACK包丢失，就会出现服务端一直等待ACK包并且重传FIN包，且若此时客户端在相同环境中重新建立新连接，想要进行三次握手，服务端此时还处于LAST_ACK状态就会直接返回RST包结束握手。

如果有大量 TIME_WAIT 状态的连接会出现：

- 连接表无法复用；
- socket 结构体内存占用；

针对 TIME_WAIT 持续时间过长的问题，Linux 新增了几个相关的选项，`net.ipv4.tcp_tw_reuse` 和 `net.ipv4.tcp_tw_recycle`, 这两个参数都依赖于 TCP 头部的扩展选项：timestamp。

- 前者是重用“浪费”处于TIME_WAIT的连接；
- 通过缓存主机的最新的时间戳，决定是否丢弃还是复用TIME_WAIT连接。

##### 两个MSL

- 1 个 MSL 确保四次挥手中主动关闭方最后的 ACK 报文最终能达到对端；
- 1 个 MSL 确保对端没有收到 ACK 重传的 FIN 报文可以到达；

2MS = 去向 ACK 消息最大存活时间（MSL) + 来向 FIN 消息的最大存活时间（MSL）

##### CLOSE_WAIT

在客户端发送关闭连接请求给服务端时，服务端首先就会进入CLOSE_WAIT状态，直至等到自身数据发送完全时才会发送FIN包同时进入LAST_ACK状态。

一般我们使用JDBC操作数据库时在完成操作时不关闭数据库的连接就会导致数据库连接不会关闭保持CLOSE_WAIT状态。

通过调整`tcp_keepalive_time`选项来控制TCP空闲连接可以存活的时间，从而调整CLOSE_WAIT状态的时间。

#### TCP保证可靠性

TCP主要通过以下几个方面实现：

- 对每个包提供校验和；
- 包的序列号解决了接收数据的乱序、重复问题；
- 超时重传；
- 流量控制、拥塞控制等；

##### 校验和

每个 TCP 包首部中都有两字节用来表示校验和，防止在传输过程中有损坏。如果收到一个校验和有差错的报文，TCP 不会发送任何确认直接丢弃它，等待发送端重传。

##### 序列号

解决数据包的乱序问题，TCP会根据序列号重新进行排序；

解决数据包的重复问题，TCP根据包序号丢弃重复的数据；

##### 超时重传

超时重传即发送端向接收端发送请求时，会等待接收端的ACK进行确认，如果超过确定时间后接收端依旧没有返回ACK，则发送端会将数据包重新传送。

超时重传的时间间隔是动态变化增加的，一旦达到重传次数上限则强制关闭连接。

> 确定重传的时间间隔有以下方法：
>
> - 经典方法（平滑往返时间）
> - 标准方法（Jacobson / Karels 算法）
> - 重传二义性与 Karn / Partridge 算法

##### 流量控制

- 简单来说，让发送方的发送速率不要太快，既要让接收方来得及接收，也不要使网络发生拥塞。
- 从socket的角度来说，数据的发送接收都需要经过一个缓冲区，应用程序不断存取两端的缓冲区，流量控制要做到缓冲区已满的情况下发送端应该停止发送数据。

为了控制发送端的频率，接收端会告知客户端自己接收窗口即接收缓冲区中空余的部分，根据该窗口来调整发送策略。

![image-20201203205619193](http://img.zhengyua.cn/img/20201203205619.png)

![image-20201203205842205](http://img.zhengyua.cn/img/20201203205842.png)

> - TCP zero window
>
> 若发送端的滑动窗口变为0，经过一段时间接收端从高负载中缓过来，可以处理更多的数据包，但此时发送端不知此情况就不会发送更多的数据包，但是通过零窗口探测机制（ACK包）解决。
>
> - TCP windows full
>
> 站在发送端角度说的，表示在途字节数等于对方接收窗口的情况，此时发送端不能再发数据给对方直到发送的数据包得到 ACK。

##### 拥塞控制

防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。

拥塞处理主要涉及到下面这几个算法：

- 慢启动（Slow Start）
- 拥塞避免（Congestion Avoidance）
- 快速重传（Fast Retransmit）和快速恢复（Fast Recovery）

为了实现上面的算法，TCP 的每条连接都有两个核心状态值：

- 拥塞窗口（Congestion Window，cwnd）
- 慢启动阈值（Slow Start Threshold，ssthresh）

拥塞控制的算法的本质是**控制拥塞窗口（cwnd）的变化**。

###### 拥塞窗口

发送端能发送多少数据，主要取决于：

- 接收端还能接收到多少数据（接收窗口）；
- 自己为了避免网络拥塞主动控制不要发送过多的数据（拥塞窗口）；

###### 慢启动

因在建立连接之初无法确定接收端的接收能力，TCP将拥塞窗口的限制慢慢递增，保证每次发送的数据量不丢包，即该机制为慢启动。

###### 慢启动阈值

- 当 cwnd < ssthresh 时，拥塞窗口按指数级增长（慢启动）
- 当 cwnd > ssthresh 时，拥塞窗口按线性增长（拥塞避免）

###### 拥塞避免

当cwnd大于ssthresh时，会进入一个阶段，每一个往返RTT，拥塞窗口大约增加一个MSS大小，直到检测到拥塞为止。

![image-20201203211654487](http://img.zhengyua.cn/img/20201203211654.png)

###### 快速重传

当接收端接收到一个不按序到达的数据段时，TCP立刻发送一个重复ACK，而不用等有数据捎带确认。

当发送端收到三个及以上ACK便可以确认之前发的包丢失，于是马上进行重传，不用等到超时再重传。

根据之前返回的ACK包表示之前发送端的包全部接收到，所以能够根据最后一个收到的ACK包为界来快速重传剩下的数据包，此方式称为选择确认`SACK`。

###### 快速恢复

当收到三次重复ACK时，进入快速恢复阶段。（网络轻度拥塞）

- 拥塞阈值 ssthresh 降低为 cwnd 的一半：ssthresh = cwnd / 2；
- 拥塞窗口 cwnd 设置为 ssthresh；
- 拥塞窗口线性增加。

### Cookie

#### cookie的max-age属性设置为0

若`max-age`设置为0，则表示删除该`cookie`。cookie机制没有提供删除cookie的方法，失效的cookie会从浏览器的cookie文件或者内存中删除。

#### 设置了cookie的max-age属性为正数时关闭浏览器

若`max-age`设置为正数，表示cookie会在设定值后自动失效，浏览器会将此cookie持久化到cookie文件中，即使关闭浏览器也不会删除。

#### 设置了cookie的max-age属性为负数

若`max-age`设置为负数，表示cookie仅在本浏览器窗口以及本窗口打开的子窗口中有效，关闭窗口后该cookie失效。为临时性cookie，也不会存储到cookie文件中进行持久化，cookie的`max-age`默认值为-1。

#### 作用域

`Set-Cookie`字段中指定`domain`值（可传达的域名）和`path`值（可传达的URL路径）。

#### 安全性

涉及到的首部字段有

- `Secure`

  设置该属性表示cookie只在HTTPS下传输。

- `HttpOnly`

  设置该属性表示cookie只能通过HTTP协议传输，不能通过JS脚本传输，可预防XSS攻击。

- `SameSite`

  用来限制第三方`Cookie`，一般用来防止`CSRF`攻击。

#### 缺点

- 容量缺陷，Cookie上限只有4KB；
- 性能缺陷，Cookie紧跟域名，访问该域名下任何网址是都自动携带，但可通过作用域限制；
- 安全缺陷，纯文本方式传输，在不特殊设置下可通过脚本获取。

### HTTPS

#### HTTP与HTTPS的区别

HTTPS = HTTP + SSL/TLS

- 标准端口不同；
- HTTPS基于传输层，HTTP基于应用层；
- HTTPS更加安全，加强数据的隐私性、完整性、身份验证。

#### HTTPS的优势

弥补了HTTP的缺点：

- 数据隐私性，内容经过对称加密；
- 数据完整性，内容经过完整性验证（签名）；
- 身份认证，第三方无法伪客户端/服务器的身份；

#### HTTPS具体解决方式

- 解决内容被窃听（加解密）

  利用混合加密机制（并不能保证数据完整性），结合对称加密和非对称加密的优缺点，在交换密钥时使用非对称加密，在之后建立通信交换报文阶段使用对称加密。

- 解决内容被篡改（数字签名）

  数字签名就是将原文通过hash函数处理后得到的消息摘要经过加密。

  验证数字签名的过程有以下过程：

    - 首先发送方会将原文与数字签名（服务器私钥加密后的消息摘要）一起发送给接收方；
    - 接收方收到信息后，将原文经过与Hash函数处理得到消息摘要后，同时利用发送方的公钥解密数字签名后也能得到的消息摘要进行比对；

- 解决通信方身份遭伪装（数字证书）

  ![image-20201203090859241](http://img.zhengyua.cn/img/20201203090859.png)

#### SSL/TLS的握手过程

> SSL（Secure Sockets Layer）：安全套接层
>
> TSL（Transport Layer Security）：传输层安全
>
> SSL3.1 = TLS1.0
>
> TLS1.0、TLS1.1都被认为不安全的，直到TLS1.2、TLS1.3的出现。

TLS握手过程分为两部分：

- 传统的TLS握手为RSA握手；
- TLS1.2版本为ECDHE握手；

##### ECDHE握手

![img](https://user-gold-cdn.xitu.io/2020/3/22/17101146e26b3104?imageslim)

第一次握手过程：

1. 客户端在第一次发送HTTPS请求的时候，会把client_random、TLS版本号、加密套件列表发送给服务器（client_hello）；
2. 服务器在接收到信息之后确认TLS的版本号，同时发送server_random、server_params、需要使用的加密套件（server_hello）、以及自己的证书（server_certificate）给客户端。

第二次握手过程：

1. 客户端在收到信息后，首先向CA机构验证服务器发送的证书，验证成功后会传递一个client_params给服务器（client_key_exchange）；
2. 同时客户端会通过ECDHE算法计算出一个pre_random，其中需要传入两个参数分贝是client_params和server_params；
3. 客户端将拥有的三个随机数分别是client_random、server_random、pre_random通过一个伪随机函数计算得出最终的secret，这个secret就是它们后续通信所要用的密钥；
4. 在客户端生成secret后会给服务器发送一个client_done信息，即确定以后通信使用第一次约定好的对称加密（change_cipher_spec）；
5. 服务器在接收client_params信息后以同样的方式得到secret，并且也会发送一个server_done消息给客户端；
6. 当双方都受到done信息并验证成功后，握手结束。以后通信就开始使用约定好的secret密钥对报文进行对称加密传输。

> （ECDHE基于**椭圆曲线离散对数**，传入的两个参数也被叫做**椭圆曲线的公钥**）

##### RSA握手

1. 首先客户端发送client_random、TSL版本号、加密套件列表给服务端；
2. 服务端接收到信息后确认TSL版本号，同时会发送server_random、需要使用的加密套件及证书给客户端；
3. 客户端收到信息后，首先对服务器的证书进行验证，若验证成功的话则会利用服务器中的公钥加密经过RSA算法生成一个pre_random发送给服务端；
4. 此时客户端将得到的三个随机数经过一个伪随机函数计算得到最终的secret，这个secret就是以后加密通信所使用的对称密钥；
5. 服务端接收到了pre_random后利用自己的私钥解密，得到pre_random后利用和客户端同样的方法生成secret；
6. 建立连接后用这个secret对称密钥加密报文传输；

##### 两种握手方式的区别

区别主要是：

- 生成secret（对称密钥）的过程不同。RSA握手是经过RSA算法得到pre_random，然后利用服务端的公钥进行加密后发送给服务端，同时经过一个伪随机函数生成的secret；而ECDHE握手是没有使用RSA算法，而是ECDHE算法生成给的pre_random，且参数是client_params和server_params；
- 在生成secret后ECDHE握手在客户端发送完client_done信息后可以抢跑，直接发送HTTP报文，节省了一个RTT，不必等到client_done信息到达服务器且返回给自己。这个过程叫`TLS False Start`；
- ECDHE具有RSA没有的向前安全性（一次破解并不影响历史信息的性质），ECDHE在每次握手的时候都会产生一个临时的密钥对(也就是client_params、server_params)。

#### TSL1.3版本的改进

- 强化安全

  废除很多加密算法，只保留了5个加密套件；

  > 如因PRAEK攻击废除了RSA算法。

- 提高性能

  同时利用会话复用节省了重新生成密钥的时间，利用 PSK 做到了0-RTT连接。

##### 0-RTT

- TLS1.2建立加密连接的过程一把需要2-RTT完成握手，在使用Session Ticket的情况下需要1-RTT；

- 在完全握手情况下，TLS1.3需要1-RTT建立连接。

  > 与TLS1.2不同的是，握手过程移除了ServerKeyExchange、ClientKeyExchange，DH参数通过key_share传输。

- TLS1.3恢复会话可以直接发送加密后的数据，不需要额外的TLS握手，即0-RTT，需要知道0-RTT握手指恢复加密传输层会话不需要额外的RTT；

- TLS1.3 0-RTT不保证前向安全性，对于TLS1.3来说缓解该问题需要通过设置`ServerConfiguration`中的`Expiration Date`字段，使得`Session Ticket Key`相关的DH静态参数在短时间内过期；

![image-20201203151725179](http://img.zhengyua.cn/img/20201203151725.png)

##### QUIC RTT

- 当客户端首次发起QUIC连接时，客户端会给服务器发送一个`clinet_hello`消息，服务器回复一个`server_reject`消息，其中包含`server config`，类似于TLS1.3的`key_share`交换；
- 当客户端获取到`server_config`后直接计算出密钥，发送应用数据了，此时可以认为是0-RTT。

因此，QUIC握手除去首次连接需要1-RTT，理论上后续握手都是0-RTT的。

[QUIC]([https://liudanking.com/network/tls1-3-quic-%E6%98%AF%E6%80%8E%E6%A0%B7%E5%81%9A%E5%88%B0-0-rtt-%E7%9A%84/](https://liudanking.com/network/tls1-3-quic-是怎样做到-0-rtt-的/))（`UDP+QUIC Crypto`）在功能层面等价于`TCP+TLS`, 并且其加密协议(`QUIC Crypto`)未来会被`TLS1.3`代替。在HTTP/2的应用场景中，QUIC可以有效的降低首次连接的RTT次数，并且支持连接迁移、FEC以及更加灵活高效的拥塞控制，因此可以在移动网络、弱网环境提供低延迟的用户体验。
